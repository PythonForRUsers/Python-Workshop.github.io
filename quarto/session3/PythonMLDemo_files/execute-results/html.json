{
  "hash": "9168d96a96ee69d30d2907d4361d7a5b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Python Logistic Regression Demo\"\nauthor: \"Python Group\"\nformat: \n    html:\n        output-file: \"session3.html\"\n        toc: true\n        code-copy: true\n        code-line-numbers: true\n        link-external-icon: false\n        link-external-newwindow: true\n---\n\n\n\n\n## Links\n\n<a href=\"https://www.kaggle.com/datasets/erdemtaha/cancer-data/data\" class=\"link-block\">\n    <img src=\"../icons/csv.png\" alt=\"Dataset\">\n    <p>Cancer Dataset</p>\n</a> <a href=\"https://github.mskcc.org/Python-Workshop/Python-Workshop.github.io/tree/main/FollowAlong\" class=\"link-block\">\n    <img src=\"../icons/code.png\" alt=\"File\">\n    <p>Download Follow Along File</p>\n</a>\n\nWe are using the same dataset as in sesssion 3! There is no need to re-download it!\n\n## Getting Started\n\nBefore doing anything else, we should first activate the conda environment we want to use. \n<details>\n<summary> Refresher: How to activate conda environment </summary>\n<div style=\"sp\"></div>\nFrom terminal, type: \n  \n<div class=\"terminal\">\n\\> conda activate ENVNAME\n</div>\n  <div style=\"margin: 10px 0;\"></div>\nWhen in VS code, you might get a popup message like the one below, confirming that the environment was activated:  \n\n<div style=\"border-left: 4px solid #007bff; background-color: #f8f9fa; padding: 5px; margin: 5px 0;\">\nSelected conda environment was successfully activated, even though \"(ENVNAME)\" indicator may not be present in the terminal prompt. \n</div>\n\nor\n\nIn Anaconda Navagator, click on the **Environments** tab on the left and select the environment you want to activate. Just selecting the environment should activate it. \n</details>\n\nIf we want to make sure we have the packages we'll need installed in the environment before we try to import them, we can either check on anaconda or use the terminal: \n\n<div class=\"terminal\">\n\\> conda list\n</div>\n<div style=\"sp\"></div>\nOtherwise, we will get an error message if we try to import packages that are not installed. \n\n<details>\n<summary> Refresher: How to install packages </summary>\n\nTo install packages, we can either use the \"anaconda\" dashboard, or we can use the command line. Make sure your environment is active before installing packages or the packages will not be available in your environment. \n\nTo install from the command line, we open a terminal and type: \n\n<div class=\"terminal\">\n\\> conda install {package}\n</div>\n\nor\n\n<div class=\"terminal\">\n\\> pip install {package}\n</div>\n\nWhen working with conda environments, it's best practice to install everything with conda and only use pip for packages that are not available through conda!\n</details>\n\n## Step 1: Import Packages\n\nSimilar to `library()` in R, weâ€™ll use `import` in Python. Fill in the blanks to import the necessary packages:\n\n::: {#cc8a70af .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as ___\nimport numpy as ___\nimport seaborn as ___\nimport matplotlib.pyplot as ___\n\n# Import from sklearn\nfrom sklearn.model_selection import __________\nfrom sklearn.preprocessing import __________\n\nfrom sklearn.linear_model import __________\n\nfrom sklearn.metrics import accuracy_score, roc_curve, auc\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#4ca48b59 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n## import from sklearn (scikit-learn)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import accuracy_score, roc_curve, auc\n```\n:::\n\n\n</details>\n</div>\n\n## Step 2: Read in Data and Perform Data Cleaning\n\nWe can use the `read_csv()` function from the pandas package to read in the dataset. \n\n::: {#c0ff8552 .cell execution_count=3}\n``` {.python .cell-code}\ndata = pd.read_csv(\"__________\")\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#89a2d9ab .cell execution_count=4}\n``` {.python .cell-code}\ndata = pd.read_csv(\"example_data/Cancer_Data.csv\")\n```\n:::\n\n\n</details>\n</div>\n\nWe can use the `.info()` function to show some basic information about the dataset like:  \n* the number of rows  \n* number of columns  \n* column labels  \n* column type  \n* number of non-null values in each column\n\n::: {#7d6f6d9f .cell execution_count=5}\n``` {.python .cell-code}\ndata._______()\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#5f51b95f .cell execution_count=6}\n``` {.python .cell-code}\ndata.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 569 entries, 0 to 568\nData columns (total 33 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   id                       569 non-null    int64  \n 1   diagnosis                569 non-null    object \n 2   radius_mean              569 non-null    float64\n 3   texture_mean             569 non-null    float64\n 4   perimeter_mean           569 non-null    float64\n 5   area_mean                569 non-null    float64\n 6   smoothness_mean          569 non-null    float64\n 7   compactness_mean         569 non-null    float64\n 8   concavity_mean           569 non-null    float64\n 9   concave points_mean      569 non-null    float64\n 10  symmetry_mean            569 non-null    float64\n 11  fractal_dimension_mean   569 non-null    float64\n 12  radius_se                569 non-null    float64\n 13  texture_se               569 non-null    float64\n 14  perimeter_se             569 non-null    float64\n 15  area_se                  569 non-null    float64\n 16  smoothness_se            569 non-null    float64\n 17  compactness_se           569 non-null    float64\n 18  concavity_se             569 non-null    float64\n 19  concave points_se        569 non-null    float64\n 20  symmetry_se              569 non-null    float64\n 21  fractal_dimension_se     569 non-null    float64\n 22  radius_worst             569 non-null    float64\n 23  texture_worst            569 non-null    float64\n 24  perimeter_worst          569 non-null    float64\n 25  area_worst               569 non-null    float64\n 26  smoothness_worst         569 non-null    float64\n 27  compactness_worst        569 non-null    float64\n 28  concavity_worst          569 non-null    float64\n 29  concave points_worst     569 non-null    float64\n 30  symmetry_worst           569 non-null    float64\n 31  fractal_dimension_worst  569 non-null    float64\n 32  Unnamed: 32              0 non-null      float64\ndtypes: float64(31), int64(1), object(1)\nmemory usage: 146.8+ KB\n```\n:::\n:::\n\n\n</details>\n</div>\nFrom the *info*, we can see that the column types make sense and most of the columns have no missing values. \n\nWe do have this extra column called \"Unnamed: 32\" with 0 non-null values...\nso let's drop it (remove it from the dataframe). \n\n::: {#25e7ca18 .cell execution_count=7}\n``` {.python .cell-code}\ndata.drop(columns=\"Unnamed: 32\", inplace=______)\n\n# Check that the column was removed\nprint(data.info())\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#33801eeb .cell execution_count=8}\n``` {.python .cell-code}\n## `inplace` means that we modify the original dataframe\ndata.drop(columns=\"Unnamed: 32\", inplace=True)\n\n## check that the column was removed\nprint(data.info())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 569 entries, 0 to 568\nData columns (total 32 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   id                       569 non-null    int64  \n 1   diagnosis                569 non-null    object \n 2   radius_mean              569 non-null    float64\n 3   texture_mean             569 non-null    float64\n 4   perimeter_mean           569 non-null    float64\n 5   area_mean                569 non-null    float64\n 6   smoothness_mean          569 non-null    float64\n 7   compactness_mean         569 non-null    float64\n 8   concavity_mean           569 non-null    float64\n 9   concave points_mean      569 non-null    float64\n 10  symmetry_mean            569 non-null    float64\n 11  fractal_dimension_mean   569 non-null    float64\n 12  radius_se                569 non-null    float64\n 13  texture_se               569 non-null    float64\n 14  perimeter_se             569 non-null    float64\n 15  area_se                  569 non-null    float64\n 16  smoothness_se            569 non-null    float64\n 17  compactness_se           569 non-null    float64\n 18  concavity_se             569 non-null    float64\n 19  concave points_se        569 non-null    float64\n 20  symmetry_se              569 non-null    float64\n 21  fractal_dimension_se     569 non-null    float64\n 22  radius_worst             569 non-null    float64\n 23  texture_worst            569 non-null    float64\n 24  perimeter_worst          569 non-null    float64\n 25  area_worst               569 non-null    float64\n 26  smoothness_worst         569 non-null    float64\n 27  compactness_worst        569 non-null    float64\n 28  concavity_worst          569 non-null    float64\n 29  concave points_worst     569 non-null    float64\n 30  symmetry_worst           569 non-null    float64\n 31  fractal_dimension_worst  569 non-null    float64\ndtypes: float64(30), int64(1), object(1)\nmemory usage: 142.4+ KB\nNone\n```\n:::\n:::\n\n\n</details>\n</div>\n\nThe column was successfully removed!\n\nNow, we can use `.head(5)` to show the first 5 rows of the dataset (rows 0-4). Remember that the first row is \"0\" not \"1\"!\n\n::: {#1ab49691 .cell execution_count=9}\n``` {.python .cell-code}\ndata.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 32 columns</p>\n</div>\n```\n:::\n:::\n\n\n### Recoding a Variable\n\nFor our logistic regression, the diagnosis column, which is our outcome of interest, should be 0, 1 not B, M. To fix this, we can use a *dictionary* and `.map()`. We could also use a lambda function like we did in Session 3, but dictionaries can be more convenient if there are more than 2 values to be recoded. \n\n::: {#a84afc9d .cell execution_count=10}\n``` {.python .cell-code}\n## define a dictionary\ny_recode = {\"B\": ___, \"M\": ___}\n\n## use .map to locate the keys in the column and replace with values\ndata[\"diagnosis\"] = data[\"diagnosis\"].map(________)\n\ndata.head(5)\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#ff50c1d8 .cell execution_count=11}\n``` {.python .cell-code}\n## define a dictionary\ny_recode = {\"B\": 0, \"M\": 1}\n\n## use .map() to locate the keys in the column and replace with values\n## B becomes 0, M becomes 1\ndata[\"diagnosis\"] = data[\"diagnosis\"].map(y_recode)\n\ndata.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>1</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>1</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>1</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>1</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>1</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 32 columns</p>\n</div>\n```\n:::\n:::\n\n\n</details>\n</div>\n\n## Step 3: Exploratory Data Analysis\n\nNow that our data is cleaned and we have our outcome in numeric form, we can use `.describe()` to get summary statistics for each column of the dataset. \n\n::: {#89b01713 .cell execution_count=12}\n``` {.python .cell-code}\n___.___()\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#39246be1 .cell execution_count=13}\n``` {.python .cell-code}\ndata.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.690000e+02</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>...</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.037183e+07</td>\n      <td>0.372583</td>\n      <td>14.127292</td>\n      <td>19.289649</td>\n      <td>91.969033</td>\n      <td>654.889104</td>\n      <td>0.096360</td>\n      <td>0.104341</td>\n      <td>0.088799</td>\n      <td>0.048919</td>\n      <td>...</td>\n      <td>16.269190</td>\n      <td>25.677223</td>\n      <td>107.261213</td>\n      <td>880.583128</td>\n      <td>0.132369</td>\n      <td>0.254265</td>\n      <td>0.272188</td>\n      <td>0.114606</td>\n      <td>0.290076</td>\n      <td>0.083946</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.250206e+08</td>\n      <td>0.483918</td>\n      <td>3.524049</td>\n      <td>4.301036</td>\n      <td>24.298981</td>\n      <td>351.914129</td>\n      <td>0.014064</td>\n      <td>0.052813</td>\n      <td>0.079720</td>\n      <td>0.038803</td>\n      <td>...</td>\n      <td>4.833242</td>\n      <td>6.146258</td>\n      <td>33.602542</td>\n      <td>569.356993</td>\n      <td>0.022832</td>\n      <td>0.157336</td>\n      <td>0.208624</td>\n      <td>0.065732</td>\n      <td>0.061867</td>\n      <td>0.018061</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>8.670000e+03</td>\n      <td>0.000000</td>\n      <td>6.981000</td>\n      <td>9.710000</td>\n      <td>43.790000</td>\n      <td>143.500000</td>\n      <td>0.052630</td>\n      <td>0.019380</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>7.930000</td>\n      <td>12.020000</td>\n      <td>50.410000</td>\n      <td>185.200000</td>\n      <td>0.071170</td>\n      <td>0.027290</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.156500</td>\n      <td>0.055040</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8.692180e+05</td>\n      <td>0.000000</td>\n      <td>11.700000</td>\n      <td>16.170000</td>\n      <td>75.170000</td>\n      <td>420.300000</td>\n      <td>0.086370</td>\n      <td>0.064920</td>\n      <td>0.029560</td>\n      <td>0.020310</td>\n      <td>...</td>\n      <td>13.010000</td>\n      <td>21.080000</td>\n      <td>84.110000</td>\n      <td>515.300000</td>\n      <td>0.116600</td>\n      <td>0.147200</td>\n      <td>0.114500</td>\n      <td>0.064930</td>\n      <td>0.250400</td>\n      <td>0.071460</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9.060240e+05</td>\n      <td>0.000000</td>\n      <td>13.370000</td>\n      <td>18.840000</td>\n      <td>86.240000</td>\n      <td>551.100000</td>\n      <td>0.095870</td>\n      <td>0.092630</td>\n      <td>0.061540</td>\n      <td>0.033500</td>\n      <td>...</td>\n      <td>14.970000</td>\n      <td>25.410000</td>\n      <td>97.660000</td>\n      <td>686.500000</td>\n      <td>0.131300</td>\n      <td>0.211900</td>\n      <td>0.226700</td>\n      <td>0.099930</td>\n      <td>0.282200</td>\n      <td>0.080040</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8.813129e+06</td>\n      <td>1.000000</td>\n      <td>15.780000</td>\n      <td>21.800000</td>\n      <td>104.100000</td>\n      <td>782.700000</td>\n      <td>0.105300</td>\n      <td>0.130400</td>\n      <td>0.130700</td>\n      <td>0.074000</td>\n      <td>...</td>\n      <td>18.790000</td>\n      <td>29.720000</td>\n      <td>125.400000</td>\n      <td>1084.000000</td>\n      <td>0.146000</td>\n      <td>0.339100</td>\n      <td>0.382900</td>\n      <td>0.161400</td>\n      <td>0.317900</td>\n      <td>0.092080</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.113205e+08</td>\n      <td>1.000000</td>\n      <td>28.110000</td>\n      <td>39.280000</td>\n      <td>188.500000</td>\n      <td>2501.000000</td>\n      <td>0.163400</td>\n      <td>0.345400</td>\n      <td>0.426800</td>\n      <td>0.201200</td>\n      <td>...</td>\n      <td>36.040000</td>\n      <td>49.540000</td>\n      <td>251.200000</td>\n      <td>4254.000000</td>\n      <td>0.222600</td>\n      <td>1.058000</td>\n      <td>1.252000</td>\n      <td>0.291000</td>\n      <td>0.663800</td>\n      <td>0.207500</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 32 columns</p>\n</div>\n```\n:::\n:::\n\n\n</details>\n</div>\n\nThe count column tells us the number of non-null (non-missing) values in a column. \n\n### Creating Descriptive Plots\n\nWe can also look at the number of each diagnosis reflected in the dataset in a plot using seaborn. \n\nYou can also save a plot to a variable (ex: 'p') if you want to display it later with `plt.show(p)`.\n\n::: {#fbcd495e .cell execution_count=14}\n``` {.python .cell-code}\nsns.countplot(x=\"_________\", hue=\"_________\", data=______)\nplt.title(\"Distribution of Diagnoses\")\n_____\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#1cd255ae .cell dpi='600' execution_count=15}\n``` {.python .cell-code}\nsns.countplot(x=\"diagnosis\", hue=\"diagnosis\", data=data)\nplt.title(\"Distribution of Diagnoses\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](PythonMLDemo_files/figure-html/cell-16-output-1.png){width=593 height=449}\n:::\n:::\n\n\n</details>\n</div>\n\nIf we want, we can change the colors of the plot. To make the plot a bit more useful, we can also change the y-scale from \"count\" to \"percentage\" and add labels so it is clear what \"0\" and \"1\" mean. \n\nTo help us pick colors, we can use `sns.color_palette()` which will display an image with the colors in the palette. \n\n::: {#7110452c .cell execution_count=16}\n``` {.python .cell-code}\nsns.color_palette(\"colorblind\")\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<svg  width=\"550\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#0173b2;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#de8f05;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#029e73;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#d55e00;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#cc78bc;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ca9161;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"330\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#fbafe4;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"385\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#949494;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"440\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ece133;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"495\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#56b4e9;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>\n```\n:::\n:::\n\n\nTo change the colors of our plot, we can make a dictionary with the values of 'diagnosis' as keys and the hexcodes of the colors we want to use as values. \n\nWe can get the hex codes of colors from a seaborn palette using `sns.color_palette().as_hex()`.\n\n::: {#9648457d .cell message='false' execution_count=17}\n``` {.python .cell-code}\ncolor_hex = sns.color_palette(\"colorblind\")._____\n\nprint(\"The hexcodes for the 'colorblind' palette are:\\n\", ____)\n\n## if we want to make the columns green for benign and yellow for malignant\n\n## the \"-\" lets us index from the end of the list rather than the front. However, the '-1'th position is the last position (there is no '-0')\n\ncolors = {0: color_hex[__], 1: color_hex[__]}\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#958f6a22 .cell message='false' execution_count=18}\n``` {.python .cell-code}\ncolor_hex = sns.color_palette(\"colorblind\").as_hex()\n\nprint(\"The hexcodes for the 'colorblind' palette are:\\n\", color_hex)\n\n## if we want to make the columns green for benign and yellow for malignant\n\n## the \"-\" lets us index from the end of the list rather than the front.However, the '-1'th position is the last position (there is no '-0')\n\ncolors = {0: color_hex[2], 1: color_hex[-2]}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe hexcodes for the 'colorblind' palette are:\n ['#0173b2', '#de8f05', '#029e73', '#d55e00', '#cc78bc', '#ca9161', '#fbafe4', '#949494', '#ece133', '#56b4e9']\n```\n:::\n:::\n\n\n</details>\n</div>\n\nWe then create the plot and tell seaborn to use 'colors' as the palette for the graph. We can also change the 'stat' to be \"percent\", which can be more interpretable than raw counts. \n\nWe can also change the xtick labels to be \"Benign\" and \"Malignant\" instead of \"0\" and \"1\". Because we assigned the plot to the variable 'p', we can use `p.{}` to change attributes of plot 'p'.\n\nWe will also change the axis labels and set a title. Once we make these changes, we can show the finished plot. \n\n::: {#53e8040a .cell execution_count=19}\n``` {.python .cell-code}\np = sns.countplot(\n    x=\"___\",\n    hue=\"___\",\n    stat=\"___\",\n    data=data,\n    palette=colors,\n    legend=False,\n)\n\n## change the xticklabels to benign and malignant\np.set_xticks([0, 1])\np.set_xticklabels([\"___\", \"\"])\n\n## change the axes labels and title\np.set(xlabel=\"___\", ylabel=\"___\", title=\"Distribution of Diagnoses\")\n\n## add legend\nplt.legend(title=\"Diagnosis\", loc=\"upper right\", labels=[\"Benign\", \"Malignant\"])\n\n## show plot\nplt.show(p)\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#673f8e7f .cell execution_count=20}\n``` {.python .cell-code}\np = sns.countplot(\n    x=\"diagnosis\",\n    hue=\"diagnosis\",\n    stat=\"percent\",\n    data=data,\n    palette=colors,\n    legend=False,\n)\n\n## change the xticklabels to benign and malignant\np.set_xticks([0, 1])\np.set_xticklabels([\"Benign\", \"Malignant\"])\n\n## change the axes labels and title\np.set(xlabel=\"Diagnosis\", ylabel=\"Percent\", title=\"Distribution of Diagnoses\")\n\n## add legend\nplt.legend(title=\"Diagnosis\", loc=\"upper right\", labels=[\"Benign\", \"Malignant\"])\n\n## show plot\nplt.show(p)\n```\n\n::: {.cell-output .cell-output-display}\n![](PythonMLDemo_files/figure-html/cell-21-output-1.png){width=585 height=449}\n:::\n:::\n\n\n</details>\n</div>\n\nIf we wanted to, we could also make a correlation heatmap of our features using `.corr()` and `sns.heatmap()`. \n\nFor this, all of our columns must be numeric, and we should remove the 'id' column as it is not useful for correlation. We use `.select_dtypes()` to select only the numeric columns from the dataset.\n\n::: {#94a5bb2a .cell execution_count=21}\n``` {.python .cell-code}\nnumeric_data = data.select_dtypes(include=___)\n\n## drop id column\nnumeric_data.drop(columns=___, inplace=___)\n\n## set figure size\nplt.figure(figsize=(20, 20))\n\n## use corr function and seaborn heatmap to create correlation heatmap\n## 'fmt' allows us to choose the number display format for the heatmap\n\nsns.heatmap(numeric_data.___, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n\n## set plot title and show plot\nplt.title(\"Feature Correlation Heatmap\")\n\nplt.___\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#754f6301 .cell execution_count=22}\n``` {.python .cell-code}\nnumeric_data = data.select_dtypes(include=[np.number])\n\n## drop id column\nnumeric_data.drop(columns=\"id\", inplace=True)\n\n## set figure size\nplt.figure(figsize=(20, 20))\n\n## use corr function and seaborn heatmap to create correlation heatmap\n## 'fmt' allows us to choose the number display format for the heatmap\n\nsns.heatmap(numeric_data.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n\n## set plot title and show plot\nplt.title(\"Feature Correlation Heatmap\")\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](PythonMLDemo_files/figure-html/cell-23-output-1.png){width=1572 height=1690}\n:::\n:::\n\n\n</details>\n</div>\n\n## Step 4: Data Setup\n\n### Splitting Training and Test Data\n\nWe first need to split the dataset into X (predictors/features) and y (outcomes). Then we use the `train_test_split()` function to split these datasets into a training dataset and a test dataset. \n\nWe use the .loc function and \":\" to select all rows and any columns including and after \"radius_mean\", and we assign these columns to x. This excludes the \"diagnosis\" and \"id\" columns. \n\nWe set y as simply the diagnosis column. \n\nWhen splitting our dataset, we can define 'test_size' which is the proportion of the data that will be set aside for testing the model. We can also set a random_state. \n\n<div style=\"border-left: 4px solid #007bff; background-color: #f8f9fa; padding: 5px; margin: 5px 0;\">\nUnlike R, Python allows for multi-argument returns from functions. This lets us assign each returned object to a different variable to be used later!\n</div>\n\n::: {#c4b41346 .cell execution_count=23}\n``` {.python .cell-code}\nx = data.loc[:, \"___\"::]\n\n## set only the diagnosis column as \"y\"\ny = data.loc[:, \"___\"]\n\n## here we assign each object returned from `train_test_split` to a different variable\n## we can use test_size to set the proportion of the dataset reserved for testing\nX_?, X_?, y_?, y_? = train_test_split(\n    x, y, test_size=0.2, random_state=42\n)\n\nX_train.head(3)\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#3e0ae5d1 .cell execution_count=24}\n``` {.python .cell-code}\nx = data.loc[:, \"radius_mean\"::]\n\n## set only the diagnosis column as \"y\"\ny = data.loc[:, \"diagnosis\"]\n\n## here we assign each object returned from `train_test_split` to a different variable\nX_train, X_test, y_train, y_test = train_test_split(\n    x, y, test_size=0.2, random_state=42\n)\n\nX_train.head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>68</th>\n      <td>9.029</td>\n      <td>17.33</td>\n      <td>58.79</td>\n      <td>250.5</td>\n      <td>0.10660</td>\n      <td>0.14130</td>\n      <td>0.31300</td>\n      <td>0.04375</td>\n      <td>0.2111</td>\n      <td>0.08046</td>\n      <td>...</td>\n      <td>10.31</td>\n      <td>22.65</td>\n      <td>65.50</td>\n      <td>324.7</td>\n      <td>0.14820</td>\n      <td>0.4365</td>\n      <td>1.2520</td>\n      <td>0.17500</td>\n      <td>0.4228</td>\n      <td>0.1175</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>21.090</td>\n      <td>26.57</td>\n      <td>142.70</td>\n      <td>1311.0</td>\n      <td>0.11410</td>\n      <td>0.28320</td>\n      <td>0.24870</td>\n      <td>0.14960</td>\n      <td>0.2395</td>\n      <td>0.07398</td>\n      <td>...</td>\n      <td>26.68</td>\n      <td>33.48</td>\n      <td>176.50</td>\n      <td>2089.0</td>\n      <td>0.14910</td>\n      <td>0.7584</td>\n      <td>0.6780</td>\n      <td>0.29030</td>\n      <td>0.4098</td>\n      <td>0.1284</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>9.173</td>\n      <td>13.86</td>\n      <td>59.20</td>\n      <td>260.9</td>\n      <td>0.07721</td>\n      <td>0.08751</td>\n      <td>0.05988</td>\n      <td>0.02180</td>\n      <td>0.2341</td>\n      <td>0.06963</td>\n      <td>...</td>\n      <td>10.01</td>\n      <td>19.23</td>\n      <td>65.59</td>\n      <td>310.1</td>\n      <td>0.09836</td>\n      <td>0.1678</td>\n      <td>0.1397</td>\n      <td>0.05087</td>\n      <td>0.3282</td>\n      <td>0.0849</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 30 columns</p>\n</div>\n```\n:::\n:::\n\n\n</details>\n</div>\n\n### Scaling/Normalizing Data\n\nBecause all of our features have different scales, we need to standardize (normalize) our dataset. We can do this by creating an instance of the `StandardScaler` class called \"scaler\" and fitting that to the training data. We then use the same \"scaler\" to scale the test dataset.\n\n::: {#6a63fbc8 .cell execution_count=25}\n``` {.python .cell-code}\n## standardize dataset\nscaler = ___()\n\n## fit the scaler to the _ data\nscaler.fit(___)\n\n## apply the scaler to the _ data and _ data\nX_train = scaler.transform(___)\nX_test = scaler.transform(___)\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#c8cd9553 .cell execution_count=26}\n``` {.python .cell-code}\n## standardize dataset\nscaler = StandardScaler()\n\n## fit the scaler to the TRAINING data\nscaler.fit(X_train)\n\n## apply the scaler to BOTH the training and test data\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n```\n:::\n\n\n</details>\n</div>\n## Step 5: Model Setup\n\nNext we have to set up the model itself by creating an instance of the `LogisticRegression` model class. \n\n::: {#e399d3af .cell execution_count=27}\n``` {.python .cell-code}\nlr = ___\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#71ed5e61 .cell execution_count=28}\n``` {.python .cell-code}\nlr = LogisticRegression()\n```\n:::\n\n\n</details>\n</div>\nThen, we can fit this model to the training data.\n\n::: {#17a61400 .cell execution_count=29}\n``` {.python .cell-code}\n## fit to training data\nlr.___(X_train, y_train)\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#4bd2af22 .cell execution_count=30}\n``` {.python .cell-code}\n## fit to training data\nlr.fit(X_train, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\n</details>\n</div>\n\n## Step 6: Look At Results\n\nOnce the model is fit, we can use it to predict the outcome (diagnosis) based on the features of the test data. \n\n### Store Results in a Dataframe\n\nWe can use `pd.DataFrame()` to create an empty pandas dataframe that we can fill with our results. \n\n::: {#749db3c7 .cell execution_count=31}\n``` {.python .cell-code}\n## use model to predict test data\n## set up dataframe to review results\nresults = pd.___\n\n## get predicted\nresults.loc[:, 'Predicted']= lr.___(___)\n\n## get true y values for test dataset\nresults.loc[:, 'Truth'] = ___.___\n\n## get probability of being malignant\n## the output is one probability per outcome, we only want the second outcome (malignant)\nresults.loc[:, 'Probability: Malignant'] = pd.DataFrame(lr.___(X_test))[_]\n\n#results_recode = {0: \"B\", 1:\"M\"}\n#results.replace({\"Predicted\": results_recode, 'Truth': results_recode}, inplace = True)\n\nresults.head(5)\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#ca82550f .cell execution_count=32}\n``` {.python .cell-code}\n## use model to predict test data\n## set up dataframe to review results\nresults = pd.DataFrame()\n\n## get predicted\nresults.loc[:, 'Predicted']= lr.predict(X_test)\n\n## get true y values for test dataset\nresults.loc[:, 'Truth'] = y_test.values\n\n## get probability of being malignant\n## the output is one probability per outcome, we only want the second outcome (malignant). The second outcome uses index 1\nresults.loc[:, 'Probability: Malignant'] = pd.DataFrame(lr.predict_proba(X_test))[1]\n\n#results_recode = {0: \"B\", 1:\"M\"}\n#results.replace({\"Predicted\": results_recode, 'Truth': results_recode}, inplace = True)\n\nresults.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted</th>\n      <th>Truth</th>\n      <th>Probability: Malignant</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.113590</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.999991</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.996921</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000510</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000061</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n</details>\n</div>\n\nWe can also get a quantitative \"accuracy score\" that will give us an idea of how well our model predicts our outcomes. \n\n::: {#4a5ae5e1 .cell execution_count=33}\n``` {.python .cell-code}\naccuracy = accuracy_score(results[\"Truth\"], results[\"Predicted\"])\n\nprint(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 97.37%\n```\n:::\n:::\n\n\n### Create ROC curve\n\nAs a figure, we can create an ROC curve and use quarto chunk options to add a figure caption. \n\n::: {#5c41325c .cell execution_count=34}\n``` {.python .cell-code}\n## make a plot to vizualize the ROC curve\n\n## get false pos rate, true pos rate and thresholds\n## there are 3 outputs so we need 3 variables to catch them\n___, ___, ___ = roc_curve(results[\"Truth\"], results[\"Predicted\"])\n\n## get AUC data\nroc_auc = auc(___, ___)\n\n## set up plot\nplt.figure(figsize=(8, 6))\n\n## using matplotlib this time, create line plot with 2pt line weight\n## add \"ROC Curve (AUC = AUC)\" as label for orange line\n## .2f is for display formatting, lw is linewidth\nplt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n\n## create another curve, this time blue with a dashed line labeled \"Random\"\n## as in random chance.\nplt.plot(___, ___, color=\"navy\", lw=2, linestyle=\"--\", label=\"Random\")\n\n## add xlabel, ylabel and title\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\n    \"Receiver Operating Characteristic (ROC) Curve\\nAccuracy: {:.2f}%\".format(\n        accuracy * 100\n    )\n)\n\n## add legend and show plot\nplt.legend(loc=\"lower right\")\nplt.show()\n```\n:::\n\n\n<div class = \"ans\"> \n<details><summary> Click to reveal answers </summary>\n\n::: {#5cebae34 .cell execution_count=35}\n``` {.python .cell-code}\n## make a plot to vizualize the ROC curve\n\n## get false pos rate, true pos rate and thresholds\nfpr, tpr, thresholds = roc_curve(results[\"Truth\"], results[\"Predicted\"])\n\n## get AUC data\nroc_auc = auc(fpr, tpr)\n\n## set up plot\nplt.figure(figsize=(8, 6))\n\n## using matplotlib this time, create line plot with 2pt line weight\n## add \"ROC Curve (AUC = AUC)\" as label for orange line\n## .2f is for display formatting, lw is linewidth\nplt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n\n## create another curve, this time blue with a dashed line labeled \"Random\"\n## as in random chance\nplt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\", label=\"Random\")\n\n## add xlabel, ylabel and title\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\n    \"Receiver Operating Characteristic (ROC) Curve\\nAccuracy: {:.2f}%\".format(\n        accuracy * 100\n    )\n)\n\n## add legend and show plot\nplt.legend(loc=\"lower right\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![An ROC curve for our logistic regression model](PythonMLDemo_files/figure-html/cell-36-output-1.png){width=663 height=541}\n:::\n:::\n\n\n</details>\n</div>\n\nCongratulations! You have successfully done logistic regression in Python!\n\n<details>\n<summary> Citations </summary>\nIcons  \n<a href=\"https://www.flaticon.com/free-icons/csv\" title=\"csv icons\">Csv icons created by rizal2109 - Flaticon</a>\n<a href=\"https://www.flaticon.com/free-icons/ipynb\" title=\"ipynb icons\">Ipynb icons created by JunGSa - Flaticon</a>\n<a href=\"https://www.flaticon.com/free-icons/coding\" title=\"coding icons\">Coding icons created by juicy_fish - Flaticon</a>  \n</details>\n\n",
    "supporting": [
      "PythonMLDemo_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}