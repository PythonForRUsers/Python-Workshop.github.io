{
  "hash": "1d26c9d1608a8d2f2dfa96c7699650f4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: '**Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries**'\njupyter: python3\nformat: \n    revealjs:\n        theme: [default, slideshowv2.scss]\n        code-copy: true   \n        smaller: false\n        code-block-height: 850px\n        highlight-style: pygments\n        width: 1600   # default is 960\n        height: 900  # default is 700\n        transition: none\n        code-line-numbers: true\n        self-contained: true\nexecute:\n  freeze: auto\n  eval: true\n  echo: true\n  warning: false\n  error: false\n---\n\n\n## Session Overview\n\n<div class=\"clean-text\">\n\nIn this session, we'll explore how Python's object-oriented nature affects our modeling workflows. <br>\n\n<strong style=\"font-size: 1.15em\">Topics:</strong>  \n<ul>\n  <li><strong>Intro to OOP</strong> and how it makes modeling in Python different from R</li>\n  <li><strong>Building and extending classes</strong> using inheritance and mixins</li>\n  <li><strong>Applying OOP to machine learning</strong> through demos with scikit-learn</li>\n  <ul>\n    <li>Creating and using models</li>\n    <li>Plotting data with `plotnine` and `seaborn`</li>\n  </ul>\n</ul>\n\n</div>\n\n  <aside class=\"notes\">\n    This is the last session of the intro to python workshops. There will be a brief 'homework' that covers the topics in this session. I do not anticipate having much time left over at the end of this session so if you have any questions about that please feel free to reach out to us via teams!\n  </aside>\n\n# Introduction \n\n\n\n## Why Python? üêç\n<div class=\"clean-text\">\n\n::: columns\n::: column\n\n#### R: Built by Statisticians for Statisticians\n- Excels at:\n    - Statistical analysis and modeling  \n    - Clean outputs and tables from models\n    - Beautiful data visualizations with simple code  \n\n\n:::\n\n::: column\n\n#### Python: General-Purpose Language\n- Excels at: \n    - Machine Learning, Neural Networks & Deep Learning (scikit-learn, PyTorch, TensorFlow)   \n    - Image & Genomic Data Analysis (scikit-image, biopython, scanpy)\n    - Software & Command Line Interfaces, Web Scraping, Automation\n\n:::\n:::\n\n\nPython‚Äôs broader ecosystem makes it the go-to language in domains like AI, bioinformatics, data engineering, and computational biology.  \n\n> **Note:** Packages like `rpy2` and `reticulate` make it possible to use both R and Python in the same project, but those are beyond the scope of this course.  \n> A primer on `reticulate` is available here: [https://www.r-bloggers.com/2022/04/getting-started-with-python-using-r-and-reticulate/](https://www.r-bloggers.com/2022/04/getting-started-with-python-using-r-and-reticulate/)\n</div>\n\n  <aside class=\"notes\">\nAs we talked about in session 1, R and Python have different strengths. R was designed for statistics and excels at statistical analysis & modeling, clean outputs and beautiful visualizations. Python is a general purpose programming language that excels at things like machine learning, image/genomic analysis and software. \n\nPython's broader ecosystem makes it the go-to language for things like AI, bioinformatics, data engineering and computational biology. \n\nThere are packages like rpy2 (for python) and reticulate (for R) that make it possible to use both R and python in the same project, but those are beyond the scope of this course. \n  </aside>\n\n## Programming Styles: R vs Python\n<div class=\"clean-text\">\n<br>\nIn the first session, we talked briefly about functional vs object-oriented programming:   \n<br>\n\n>  <span style=\"color: #007acc\"><strong>Functional programming:</strong></span> focuses on functions as the primary unit of code <br>\n>  <span style=\"color: #007acc\"><strong>Object-oriented programming:</strong></span> uses objects with attached attributes(data) and methods(behaviors) <br>\n\n- R leans heavily on the functional paradigm ‚Äî you pass data into functions and get back results, in most cases without altering the original data. Functions and pipes (%>%) dominate most workflows.\n\n- In Python, <span style=\"color: #007acc\"><strong>everything is an object</strong></span>, even basic things like lists, strings, and dataframes. A lot of 'functions' are instead written as object-associated methods. Some of these methods modify the objects in-place by altering their attributes. <span style=\"color: #007acc; font-weight:bold\">Understanding how this works is key to using Python effectively!</span>\n\n> You‚Äôve already seen this object-oriented style in Sessions 2 and 3 ‚Äî you create objects like lists or dataframes, then call methods on them like `.append()` or `.sort_values()`. In python, instead of piping, we sometimes chain methods together.\n</div>\n\n  <aside class=\"notes\">\nIn the first session we briefly mentioned functional vs object-oriented programming. Functional programming uses functions asa the primary unit of code while object-oriented programming uses objects with attached attributes (data) and methods (behaviors). \n\nWhen we're programming in R, we typically use (and sometimes write) functions that we pass data into and get back results without altering the original data. Functions and pipes dominate most workflows. \n\nIn python, we use objects. Everything is an object (lists, strings, dataframes, etc) and a lot of 'functions' are written as object-associated methods. Some of these methods modify the objects in place by altering their attributes instead of returning a new object. Understanding this is key to using python effectively. \n  </aside>\n\n\n## Modeling in Python \n<div class=\"small-clean-text\">\n<span style=\"color: #007acc\"><strong>Python absolutely uses **functions**‚Äîjust like R!</strong></span>\nThey're helpful for **data transformation**, **wrangling**, and **automation tasks** like looping and parallelization. <br>\n\nBut when it comes to **modeling**, libraries are designed around **classes**: blueprints for creating objects that store data (**attributes**) and define behaviors (**methods**).  <br>\n\n  - `scikit-learn` is great for getting started‚Äîeverything follows a simple, consistent OOP interface. Its API is also consistant with other modeling packages, like [xgboost](https://xgboost.readthedocs.io/en/release_3.0.0/) and [scvi-tools](https://docs.scvi-tools.org/en/stable/index.html).\n  - [<u>`scikit-survival`</u>](https://scikit-survival.readthedocs.io/en/stable/) is built on top of `scikit-learn`. [https://scikit-survival.readthedocs.io/en/stable/user_guide/00-introduction.html](https://scikit-survival.readthedocs.io/en/stable/user_guide/00-introduction.html) is a good tutorial for it.\n  - `PyTorch` and `TensorFlow` are essential if you go deeper into neural networks or custom models‚Äîyou‚Äôll define your **own model classes** with attributes and methods, but the basic structure is similar to `scikit-learn`.  \n  - [<u>`statsmodels`</u>](https://www.statsmodels.org/stable/gettingstarted.html) is an alternative to `scikit-learn` for statistical analyses and has R-like syntax and outputs. It's a bit more complex than `scikit-learn` and a bit less consistant with other packages in the python ecosystem. *[https://wesmckinney.com/book/modeling](https://wesmckinney.com/book/modeling) is a good tutorial for statsmodels.*\n\n> üí° To work effectively in Python, especially for tasks involving modeling or model training, <span style=\"color: #007acc\"><strong>it helps to think in terms of objects and classes, not just functions.</strong></span>   \n</div>\n\n  <aside class=\"notes\">\nEven though python is more object focused, it still uses functions! They are particualrly helpful for things like data transformation, data wrangling and automation tasks like looping and parallelization. However, when it comes to modeling, libraries are designed around classes, which are like blueprints for creating objects that store data and define behaviors. \n\nThese are some of the most commonly used modeling libraries in python. For this session, we will focus on scikit-learn, which is relatively simple and follows a consistent interface. Its API (Application Programming Interface) is also consistant with other modeling packages like xgboost and scvi-tools. scikit-survival is built off of scikit-learn and therefore has a similar API. \n\nPytorch and tensorflow are more complex but essential for neural networks/deep learning models. With these packages, you define your own model classes, but the basic class structure is similar to sklearn. \n\nFinally, there is statsmodels, which is an alternative to sklearn for statistical analyses. It has R-like syntax and outputs and is a bit more complicated to use than sklearn. Personally, if I wanted R-like outputs I'd use reticulate or just save my data and re-load in R, but statsmodels is available if needed. \n  </aside>\n\n\n## Why Does OOP Matter in Python Modeling? \n<div class=\"clean-text\">\n<strong>In Python modeling frameworks:</strong>\n</p>\n\n<ul style=\"line-height: 1.15; margin-top: 0;\">\n  <li>Models are <strong>instances of classes</strong></li>\n  <li>You call methods like <code>.fit()</code>, <code>.predict()</code>, <code>.score()</code></li>\n  <li>Internal model details like coefficients or layers are stored as <strong>attributes</strong></li>\n</ul>\n\n<p style=\"margin-top: 0.5em; margin-bottom: 0.75em;\">\nThis makes model behavior <strong>consistent</strong> between model classes and even libraries. It also <strong>simplifies</strong> creating/using pre-trained models: both the architecture and learned weights are bundled into a single object with expected built-in methods like `.predict()` or `.fine_tune()`.\n</p>\n\n<blockquote style=\"margin-top: .75em;\">\n  Instead of having a separate results object, like in R, you would retrieve your results by accessing an attribute or using a method that is attached to the model object itself. \n</blockquote>\n<br>\n\n<span style=\"color: #007acc; font-size: 0.95em;\"> <strong><em>We‚Äôll focus on `scikit-learn` in this session, but these ideas carry over to other libraries like `xgboost`, `statsmodels`, and `PyTorch`.</em></strong> </span> \n</div>\n\n  <aside class=\"notes\">\nSo why is OOP so important for python modeling? First, models in python are instances of classes that have attahced methods like fit, predict and score. The internal model details like coefficients or layers are stored as attributes. \n\nDefinining models as instances of classes is useful because it makes model behavior consistant between model classes (due to inheritance which i'll explain more about shortly) and even libraries. It also simplifies creating/using pre-trained models because the model architecture and learned weights are bundled into a single object that can be loaded. Expected built-in methods are also included in this bundle. \n\nAdditionally, instead of having a separate results object like in R, you can retrieve your results by either accessing an attribute or using a method attached to the model object itself. \n  </aside>\n\n# Part 1: Object-Oriented Programming {.smaller}\n\n## **Key OOP Principles (Recap)**\n\n<div class=\"smaller-clean-text\">\nIn OOP, code is structured around **objects** (as opposed to functions). This paradigm builds off the following principles: \n\n::: {.fragment}\n1. **Encapsulation**: Bundling data and methods together in a single unit.  \n   - A `StandardScaler` object stores mean and variance data and has `.fit()` and `.transform()` methods\n:::\n\n::: {.fragment}\n2. **Inheritance**: Creating new classes based on existing ones.  \n   - `sklearn.LinearRegression` inherits attributes and methods from a general regression model class.   \n:::\n::: {.fragment}\n3. **Abstraction**: Hiding implementation details and exposing only essential functionality.  \n   - e.g., `.fit()` works the same way from the outside, regardless of model complexity  \n:::\n::: {.fragment}\n4. **Polymorphism**: Objects of different types can be treated the same way if they implement the same methods. \n    - Python‚Äôs **duck typing**:  \n      - ü¶Ü *\"If it walks like a duck and quacks like a duck, then it must be a duck.\"* ü¶Ü  \n      - ex: If different objects all have a .summarize() method, we can loop over them and call .summarize() without needing to check their class. As long as the method exists, Python will know what to do.\n      - This lets us easily create [<u>pipelines</u>](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) that can work for many types of models.  \n\n>We won't cover [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) here, but they are worth looking into!\n:::\n</div>\n\n  <aside class=\"notes\">\nIf you read through the OOP pre-reading this will be a review. In OOP, code is structured around objects and this paradigm builds off of the following principles: \n1: Encapsulation - bundling data and methods together in a single unit. For example, an object of the `Standard Scalar` class, which we'll use later, stores mean and variance data and has fit and transform methods. \n2: Inheritance - which allows us to create new classes that inherit attributes and methods from existing classes. For example, the lienar regression model class in sklearn inherits attributes and methods from a general regression model class\n3: Abstraction - hiding implementation detals and exposing only essential functionality\n    For example, the fit method works the same way from the outside regardless of model complexity\n4: Polymorphism means we can treat objects of different types the same way‚Äîas long as they implement the same method.\n\nIn Python, this is done through something called duck typing, which comes from the phrase:\n\"If it walks like a duck and quacks like a duck, it's probably a duck.\"\nIn other words, Python doesn‚Äôt care what class an object is‚Äîit just checks whether it has the method you're trying to call.\n\nSo if three different objects each have a .summarize() method, we can loop through them and call .summarize() without needing to check their type first. As long as the method exists and accepts the right arguments, Python will just run it.\nThis flexibility is one of the biggest reasons OOP is so useful for machine learning. Most model classes in Python‚Äîwhether it‚Äôs logistic regression, random forests, or a neural network‚Äîcome with a standard set of methods like .fit(), .predict(), and .score().\nThat consistency means we can swap models in and out with very little change to our code. It also makes it easy to build reusable code‚Äîlike pipelines‚Äîthat can work across different model types without needing special handling for each one.\n  </aside>\n\n## **Classes and Objects** \n<div class=\"clean-text\">\n\n**Classes** are **blueprints** for creating objects. Each object contains:  \n<ul style=\"font-size: .8em; line-height: 1.2;\">\n    <li><strong>Attributes</strong> (data): model coefficients, class labels</li>\n    <li><strong>Methods</strong> (behaviors): <code>.fit()</code>, <code>.predict()</code></li>\n</ul>\n\n<span style=\"font-size: .8em;\">üëâ To Get the class of an object, use:</span>\n\n::: {#30e0b2e3 .cell execution_count=1}\n``` {.python .cell-code}\ntype(object) # Returns the type of the object\n```\n:::\n\n\n<span style=\"font-size: .8em;\">üëâ To check if an object is an instance of a particular class, use:</span>\n\n::: {#a121757e .cell execution_count=2}\n``` {.python .cell-code}\nisinstance(object, class)  # Returns True if `object` is an instance of `class`.\n```\n:::\n\n\n<br>\n\n<p style=\"color: #007acc; font-weight: 600;\">\nKnowing what class an object belongs to helps us understand what methods and attributes it provides.\n</p>\n</div>\n\n<aside class=\"notes\">\nLike I mentioned earlier, classes are blueprints for creating objects which contain attributes (data) like model coefficients or labels and methods like fit and predict. \n\nTo get the class of an object in python, we can use the 'type' function. To check if an object is an instance of a particular class, we can use the 'isinstance' function. \n\nKnowing what class an object belongs to can help us understand what methods and attibutes it should have, but we do not need to know class to use a method. \n</aside>\n\n# Example: Creating a Class\n\n## Base Classes \n<div class=\"clean-text\">\n\nA **base class** (or parent class) serves as a template for creating objects. Other classes can inherit from it to reuse its properties and methods.\n\nClasses are defined using the `class` keyword, and their structure is specified using an `__init__()` method for initialization. \n\n::: {.fragment}\n\nFor example, we can define a class called `Dog` and give it attributes that store data about a given dog and methods that represent behaviors an object of the `Dog` class can perform. We can also edit the [**special** or **\"dunder\"** methods](https://docs.python.org/3/reference/datamodel.html#special-method-names) (short for double underscore) that define how objects behave in certain contexts. \n\n::: {#925df44e .cell execution_count=3}\n``` {.python .cell-code code-line-numbers=\"1-2|3,4|6-7|9-13\"}\nclass Dog: ## begin class definition\n    def __init__(self, name, breed): ## define init method\n        self.name = name ## add attributes\n        self.breed = breed\n\n    def speak(self): ## add methods\n        return f\"{self.name} says woof!\"\n\n    def __str__(self): # __str__(self) tells python what to display when an object is printed\n        return f\"Our dog {self.name}\"\n\n    def __repr__(self): # add representation to display when dog is called in console\n        return f\"Dog(name={self.name!r}, breed={self.breed!r})\"\n```\n:::\n\n\n:::\n</div>\n\n<aside class=\"notes\">\nA base class serves as a template for creating objects and other classes can inherit its attributes and methods. Classes are defined using the 'class' keyword and their structure is specified using an init method for initialization. \n\nFor example, we can create a class called Dog and give it attributes and methods. We can also edit special or dunder methods that define how objects of this class behave in certain contexts. \n\nFirst we will define our init method, which sets up the structure for objects of the dog class. The parameters here (name and breed) can be stored as attributes. The speak method here defines the speech behavior for the dog and returns a string, that changes based on the value stored in the 'name' attribute. \n\nWe can also define our str and repr methods which tell python what to do when an object is printed (str) or called in console (repr). These methods are useful for displaying information about objects at a glance. We will see an interesting example of a repr method later on. \n\n</aside>\n\n## Creating a dog\n<div class=\"clean-text\">\n\nCreating an instance of the `Dog` class lets us model a particular dog:  \n\n::: {#1a7520bc .cell output-location='fragment' execution_count=4}\n``` {.python .cell-code}\nbuddy = Dog(\"Buddy\", \"Golden Retriever\")\nprint(f\"Buddy is an object of class {type(buddy)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBuddy is an object of class <class '__main__.Dog'>\n```\n:::\n:::\n\n\n<ul>\n    <li>We set the value of the attributes [`name` and `breed`], which are then stored as part of the `buddy` object </li>   \n    <li> We can use any methods defined in the Dog class on `buddy` </li>   \n</ul>  \n\n::: {#b65c501c .cell output-location='fragment' execution_count=5}\n``` {.python .cell-code code-line-numbers=\"1-3|5-6|8-9\"}\n## if we want to see what kind of dog our dog is\n## we can call buddy's attributes\nprint(f\"Our dog {buddy.name} is a {buddy.breed}.\")\n\n## we can also call any Dog methods\nprint(buddy.speak())  \n\n## including special methods\nbuddy ## displays what was in the __repr__() method\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOur dog Buddy is a Golden Retriever.\nBuddy says woof!\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=75}\n```\nDog(name='Buddy', breed='Golden Retriever')\n```\n:::\n:::\n\n\n<span style=\"color: #007acc\"><strong>Note:</strong> For python methods, the `self` argument is assumed to be passed and therefore we do not put anything in the parentheses when calling `.speak()`. For attributes, we do not put () at all.</span>\n\n</div>\n\n<aside class=\"notes\">\nIf we want to model a particular dog, we create an instance of the dog class. The arguments we pass to `Dog` set the name and breed of the dog.\n\nIf we want to prove that buddy is an object of class dog, we can use type(buddy).\n\nOnce we create buddy, we can use any attributes or methods defined in the dog class. \n</aside>\n\n## Derived (Child) Classes  \n<div class=\"clean-text\">\n\nDerived/child classes build on base classes using the principle of inheritence. <br>\n\nNow that we have a `Dog` class, we can build on it to create a specialized `GuardDog` class. \n\n::: {#309bb6b7 .cell execution_count=6}\n``` {.python .cell-code code-line-numbers=\"|1|2-7|\"}\nclass GuardDog(Dog):  # GuardDog inherits from Dog\n    def __init__(self, name, breed, training_level): ## in addition to name and breed, we can \n        # define a training level. \n        # Call the parent (Dog) class's __init__ method\n        super().__init__(name, breed)\n        self.training_level = training_level  # New attribute for GuardDog that stores the \n        # training level for the dog\n\n    def guard(self): ## checks if the training level is > 5 and if not says train more\n        if self.training_level > 5:\n            return f\"{self.name} is guarding the house!\"\n        else:\n            return f\"{self.name} needs more training before guarding.\"\n    \n    def train(self): # modifies the training_level attribute to increase the dog's training level\n        self.training_level = self.training_level + 1\n        return f\"Training {self.name}. {self.name}'s training level is now {self.training_level}\"\n\n# Creating an instance of GuardDog\nrex = GuardDog(\"Rex\", \"German Shepherd\", training_level= 5)\n```\n:::\n\n\n</div>\n\n<aside class='notes'>\nDerived or child classes build on base classes using the principle of inheritence. This helps us build more specialized classes without having to start from scratch.\n\nIf we want to make a new guardDog class, we can start by inheriting the attributes and methods of the dog class by putting 'Dog' in the parentheses here. \n\nWhen we define our init method, we can first call the parent class's init method to assign the dog's name and breed. We can also add an additional attribute that stores the dog's training level. \n\nBecause of inheritence, guarddogs also have the speak method, but we can also give them new methods like guard and train. The guard method, like the speak method earlier, just returns a value. However, the train method actually modifies the training_level attribute of the object in-place. This means that, if we want to train a guarddog, we do not have to assign the trained dog to a new variable to preserve the trained state. \n\nLet's make an instance of guarddog called rex and we can see how this works. \n</aside>\n\n---\n\nNow that we have a dog (rex), we can call on any of the methods/attributes introduced in the `Dog` class as well as the new `GuardDog` class.\n\nUsing methods from the base class: \n\n::: {#ce808709 .cell output-location='fragment' slide-type='fragment' execution_count=7}\n``` {.python .cell-code}\nprint(rex.speak())\nrex\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRex says woof!\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=77}\n```\nDog(name='Rex', breed='German Shepherd')\n```\n:::\n:::\n\n\n. . . \n\n<span style=\"font-size: 1.15em; color: #007acc\"><strong>This is the power of inheritance</strong></span>‚Äîwe don‚Äôt have to rewrite everything from scratch!\n\n. . . \n\nUsing a method from the child class: \n\n::: {#a0beb508 .cell output-location='fragment' slide-type='fragment' execution_count=8}\n``` {.python .cell-code}\nprint(f\"{rex.name}'s training level is {rex.training_level}.\")\nprint(rex.guard()) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRex's training level is 5.\nRex needs more training before guarding.\n```\n:::\n:::\n\n\n<aside class='notes'>\n\nOf course we can use the speak() and repr() methods that we defined for the dog class. We can also use the training method that we just defined. **adv**\n\nto successfully guard, a rex needs a training level greater than 5. Currently his level is 5, so he needs more training before guarding.\n\n</aside>\n\n---\n\nUnlike standalone functions, methods in Python often update objects in-place‚Äîmeaning they modify the object itself rather than returning a new one.\n\nWe can use the `.train()` method to increase rex's training level. \n\n::: {#c5ef1ada .cell output-location='fragment' execution_count=9}\n``` {.python .cell-code}\nprint(rex.train())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining Rex. Rex's training level is now 6\n```\n:::\n:::\n\n\n:::{.callout-important}  \n## Be Careful!!!\n\nCalling rex.train() within a print statement still updates rex's training level. If we were to do this instead:\n```{.python}\nrex.train()\nprint(rex.train())\n```\n it would train rex twice!\n:::\n\n. . . \n\nNow if we check, \n\n::: {#79b14543 .cell output-location='fragment' execution_count=10}\n``` {.python .cell-code}\nprint(f\"{rex.name}'s training level is {rex.training_level}.\")\nprint(rex.guard()) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRex's training level is 6.\nRex is guarding the house!\n```\n:::\n:::\n\n\n. . . \n\nAs with Rex, <span style=\"color: #007acc\"><strong>child classes inherit all attributes (`.name` and `.breed`) and methods (`.speak()` `__repr__()`) from parent classes.</strong></span> They can also have new methods (`.train()`).\n\n<aside class='notes'>\nUnlike standalone functions, methods like train() update objects in-place instead of returning a new object. This allows us to increase rex's training level without storing rex to a new variable. \n\nPlease note that even though we're calling rex.train() within a print statement, it still updates rex's training level! \n\nAfter training rex once, we can see that his training level is sufficient to allow him to guard! **adv**\n\nas we saw with rex, child classes inherit all attributes and methods from their parent classes, but they can also have new ones. \n\n</aside>\n\n\n## Mixins\n<div class=\"clean-text\">  \n\nA **mixin** is a special kind of class designed to add **functionality** to another class. Unlike base classes, mixins aren‚Äôt used alone.  \n\n:::{.fragment}\n\nFor example, scikit-learn uses mixins like:  \n  - `sklearn.base.ClassifierMixin` (adds classifier-specific methods)  \n  - `sklearn.base.RegressorMixin` (adds regression-specific methods)  \n\nwhich it adds to the `BaseEstimator` class to add functionality. <br> <br>\n\nTo finish up our dog example, we are going to define a mixin class that adds learning tricks to the base `Dog` class and use it to create a new class called `SmartDog`.\n:::\n</div>\n\n<aside class=\"notes\">\nMixins area special kind of class that take advantage of the inheritence property to add functionality to other classes without needing to re-define the initial class structure. Unlike base classes, mixins are not useful on their own. \n\nSome examples of mixin classes are ClassifierMixin and RegressorMixin from scikit learn, which add functionality to the BaseEstimator class. To finish up our dog example, we are going to define a mixin class that adds learning tricks to the base `Dog` class and use it to create a new class called `SmartDog`. \n</aside>\n\n---\n\nWhen creating a mixin class, we let the other base classes carry most of the initialization\n\n::: {#e212d1c2 .cell execution_count=11}\n``` {.python .cell-code code-line-numbers=\"1-2,3|4|6-20\"}\nclass TrickMixin: ## mixin that will let us teach a dog tricks\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)  # Ensures proper initialization in multi inheritance\n        self.tricks = []  # Add attribute to store tricks\n\n## add trick methods\n    def learn_trick(self, trick):\n        \"\"\"Teaches the dog a new trick.\"\"\"\n        if trick not in self.tricks:\n            self.tricks.append(trick)\n            return f\"{self.name} learned a new trick: {trick}!\"\n        return f\"{self.name} already knows {trick}!\"\n\n    def perform_tricks(self):\n        \"\"\"Returns a list of tricks the dog knows.\"\"\"\n        if self.tricks:\n            return f\"{self.name} can perform: {', '.join(self.tricks)}.\"\n        return f\"{self.name} hasn't learned any tricks yet.\"\n\n## note: the TrickMixin class is not a standalone class!\n```\n:::\n\n\n<aside class=\"notes\">\nWhen we create a mixin class, we let the base class carry most of the initialization. \n\nA mixin class can add both attributes **adv** and methods, and it can potentially work with multiple base classes. \n</aside>\n\n---\n\nBy including both `Dog` and `TrickMixin` as base classes, we give objects of class `SmartDog` the ability to speak and learn tricks!\n\n::: {#17e1e6ab .cell output-location='fragment' slide-type='fragment' execution_count=12}\n``` {.python .cell-code}\nclass SmartDog(Dog, TrickMixin):\n    def __init__(self, name, breed):\n        super().__init__(name, breed)  # Initialize Dog class\n        TrickMixin.__init__(self)  # Initialize TrickMixin separately\n\n# a SmartDog object can use methods from both parent object `Dog` and mixin `TrickMixin`.\nmy_smart_dog = SmartDog(\"Buddy\", \"Border Collie\")\nprint(my_smart_dog.speak()) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBuddy says woof!\n```\n:::\n:::\n\n\n<br>\n\n::: {#6af1e558 .cell output-location='fragment' slide-type='fragment' execution_count=13}\n``` {.python .cell-code}\nprint(my_smart_dog.learn_trick(\"Sit\"))  \nprint(my_smart_dog.learn_trick(\"Roll Over\")) \nprint(my_smart_dog.learn_trick(\"Sit\"))  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBuddy learned a new trick: Sit!\nBuddy learned a new trick: Roll Over!\nBuddy already knows Sit!\n```\n:::\n:::\n\n\n<br>\n\n::: {#eae0162f .cell output-location='fragment' slide-type='fragment' execution_count=14}\n``` {.python .cell-code}\nprint(my_smart_dog.perform_tricks()) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBuddy can perform: Sit, Roll Over.\n```\n:::\n:::\n\n\n<aside class=\"notes\">\n\nBy including both dog and trickmixin as base classes, we give smartdog objects the ability to 'speak' and learn tricks. **-adv through-**\n\n</aside>\n\n## Duck Typing \n\n\n<div class=\"clean-text\"> \n\n>ü¶Ü \"If it quacks like a duck and walks like a duck, it's a duck.\" ü¶Ü\n\nPython's duck typing makes our lives a lot easier, and is one of the main benefits of methods over functions:\n<ul>\n    <li><b>Inheritence</b> - objects inherit methods from base classes</li>\n    <li><b>Repurposing old code</b> - methods by the same name work the same for different model types</li>\n    <li><b>Not necessary to check types before using methods</b> - methods are assumed to work on the object they're attached to</li>\n</ul>\n\n\n</div>  \n\nWe can demonstrate duck typing by defining two new base classes that are different than `Dog` but also have a `speak()` method.\n\n. . . \n\n::: {#2df92821 .cell execution_count=15}\n``` {.python .cell-code code-line-numbers=\"|5-6,12-13\"}\nclass Human:\n    def __init__(self, name):\n        self.name = name\n\n    def speak(self):\n        return f\"{self.name} says hello!\"\n\nclass Parrot:\n    def __init__(self, name):\n        self.name = name\n\n    def speak(self):\n        return f\"{self.name} says squawk!\"\n```\n:::\n\n\n<aside class=\"notes\">\n\nIn my opinion python's ducktyping makes our lives a lot easier and is a good reason to use methods when possible. Duck typing makes it easy to repurpose old code with few changes - because methods by the same name work the same for different model types, even if the underlying method code is very different. Models from the same package likely share a base class, or at least can be expected to have a similar API. Duck typing also stops us from having to check object types before performing operations as methods are assumed to work on the object they're attached to. \n\nWe can demonstrate this by defining two new base classes that are different than dog but also have a speak method. **-adv-**\n\nThe human and parrot class here both have a speak method and a name attribute like the dog class. \n\n</aside>\n\n## Duck Typing in Action\n<div class=\"clean-text\">  \n\nEven though `Dog`, `Human` and `Parrot` are entirely different classes...\n\n</div>\n\n::: {#47b18601 .cell output-location='fragment' execution_count=16}\n``` {.python .cell-code}\ndef call_speaker(obj):\n    print(obj.speak())\n\ncall_speaker(Dog(\"Fido\", \"Labrador\"))\ncall_speaker(Human(\"Alice\"))\ncall_speaker(Parrot(\"Polly\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFido says woof!\nAlice says hello!\nPolly says squawk!\n```\n:::\n:::\n\n\n. . .  \n\nThey all implement `.speak()`, so Python treats them the same!\n\nIn the context of our work, this would allow us to make a pipeline using models from different libraries that have the same methods. \n\n<span style=\"font-size: 1.2em; color: #007acc\"><strong>While our dog example was very simple, this is the same way that model classes work in python!</strong></span> \n\n:::{.callout-warning}  \n\nWith duck typing, Python lets us <b><i>use methods</i></b> without breaking. It does not mean that any given method is correct to use in all cases, or that all similar objects will have the same methods.\n\n:::\n\n<aside class=\"notes\">\n\nEven though the three classes are different, we can still write a function that performs 'obj.speak()' and pass in any object with this method without having to worry about the object's class. \n\n</aside>\n\n## **Example: OOP in Machine Learning and Modeling**  \n\n<div class=\"clean-text\">  \n\nMachine learning models in Python are implemented as **classes**.    \n<ul>\n <li>When you create a model, you‚Äôre **instantiating an object** of a predefined class (e.g., `LogisticRegression()`).</li>    \n <li>That model has attributes (parameters, coefficients) and methods (like `.fit()` and `.predict()`).</li>\n</ul> \n\nFor example `LogisticRegression` is a model class that inherits from `SparseCoefMixin` and `BaseEstimator`.\n\n```{.python}\nclass LogisticRegression(LinearClassifierMixin, SparseCoefMixin, BaseEstimator):\n  \n```\n\n<span style=\"top-padding: .35em;\">To perform logistic regression, we create an instance of the `LogisticRegression` class.</span>\n\n```{.python}\n## Example: \nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()  # Creating an instance of the LogisticRegression class\nmodel.fit(X_train, y_train)   # Calling a method to train the model\npredictions = model.predict(X_test)  # Calling a method to make predictions\ncoefs = model.coef_ # Access model coefficients using attribute\n``` \n\n</div>\n\n<aside class=\"notes\">\n\nBecause models in python are defined by classes, when you create a model you are instantiating an object of a predefined class. When you fit a model and use it to make predictions, you are using methods! You can also access attributes like .coef_ to get coefficients. \n\n</aside>\n\n## **Key Benefits of OOP in Machine Learning**  \n<div class=\"clean-text\">  \n\n1. **Encapsulation** ‚Äì Models store parameters and methods inside a single object.  \n2. **Inheritance** ‚Äì New models can build on base models, reusing existing functionality.  \n3. **Abstraction**  ‚Äì `.fit()` should work as expected, regardless of complexity of underlying implimentation.\n4. **Polymorphism (Duck Typing)** ‚Äì Different models share the same method names (`.fit()`, `.predict()`), making them easy to use interchangeably, particularly in analysis pipelines. \n\nUnderstanding **base classes** and **mixins** is especially important when working with deep learning frameworks like **PyTorch and TensorFlow**, which require us to create our own model classes.  \n\n</div>\n\n<aside class=\"notes\">\n\nTo recap: python's oject oriented nature has some notable benefits for modeling and machine learning. \n\n</aside>\n\n# Part B - Demo Projects\n\n**Apply knowledge of OOP to modeling using scikit-learn**\n\n---\n\n## üêß Mini Project: Classifying Penguins with scikit-learn\n\n<div class=\"clean-text\">  \n\nNow that you understand **classes** and **data structures** in Python, let‚Äôs apply that knowledge to classify **penguin species** using two features:  \n<ul>\n<li>`bill_length_mm`</li>  \n<li>`bill_depth_mm`</li>\n</ul> \n\n\nWe‚Äôll explore:  \n\n<ul>\n<li> **Unsupervised learning** with **K-Means** clustering (model doesn't 'know' y)</li>\n<li>**Supervised learning** with a **k-NN classifier** (model trained w/ y information)</li>\n</ul>\n\nAll `scikit-learn` models are designed to have \n\n::: columns\n::: column\n**Common Methods:**  \n<ul>\n<li>`.fit()` ‚Äî Train the model </li>  \n<li>`.predict()` ‚Äî Make predictions  </li>\n</ul>    \n\n:::\n::: column\n**Common Attributes:** \n<ul>\n<li>`.classes_`, `.n_clusters_`, etc.</li>\n</ul>  \n\n:::\n:::\n> This is true of the scikit-survival package too! \n\n</div>\n\n<aside class=\"notes\">\n\nFor the rest of this session, we'll be going through 2 mini projects to classify penguin species using bill length and bill depth using kmeans and knn models from scikit-learn. In terms of API, all sklearn models are designed to have common methods like fit and predict and have some attributes like .classes_ or .n_clusters_ that store information needed to specify the model. \n\n</aside>\n\n## Import Libraries\n<div class=\"clean-text\">  \n\n<span style=\"font-size: 1.2em; color: #007acc\"><strong>Before any analysis, we must import the necessary libraries.</strong></span>  \n\nFor large libraries like **scikit-learn**, **PyTorch**, or **TensorFlow**, we usually do **not** import the entire package. Instead, we selectively import the **classes** and **functions** we need.\n\n::: columns\n::: column\n\n**Classes**  \n- `StandardScaler` ‚Äî for feature scaling  \n- `KNeighborsClassifier` ‚Äî for supervised k-NN classification  \n- `KMeans` ‚Äî for unsupervised clustering\n\n<br>\n\n> üî§ **Naming Tip**:  \n> - `CamelCase` = **Classes**  \n> - `snake_case` = **Functions**\n\n:::\n::: column\n\n**Functions**  \n- `train_test_split()` ‚Äî to split data into training and test sets  \n- `accuracy_score()` ‚Äî to evaluate classification accuracy  \n- `classification_report()` ‚Äî to print precision, recall, F1 (balance of precision and recall), Support (number of true instances per class)\n- `adjusted_rand_score()` ‚Äî to evaluate clustering performance\n:::\n:::\n\n</div>\n\n<aside class=\"notes\">\n\nOur first step is always to import any necessary libraries - but in this case, we will import specific classes and functions we plan to use. For our classes, we'll need standardscaler as well as our two model classes. We'll also import some useful functions for splitting our dataset into training/test sets and computing classification scores. \n\nA quick tip: for most python libraries, classes use CamelCase and functions use snake_case. \n\n</aside>\n\n## Import Libraries\n\n::: {#3e3e21fa .cell execution_count=17}\n``` {.python .cell-code code-line-numbers=\"|13-17|18-21\"}\n## imports\nimport pandas as pd\nimport numpy as np\n\nfrom plotnine import *\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom great_tables import GT\n\n## sklearn imports\n\n## import classes\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cluster import KMeans\n\n## import functions\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, adjusted_rand_score\n```\n:::\n\n\n## Data Preparation \n\n::: {#e0237200 .cell output-location='fragment' execution_count=18}\n``` {.python .cell-code code-line-numbers=\"1,2|4-11|13-16|18-19\"}\n# Load the Penguins dataset\npenguins = sns.load_dataset(\"penguins\").dropna()\n\n# Make a summary table for the penguins dataset, grouping by species. \nsummary_table = penguins.groupby(\"species\").agg({\n    \"bill_length_mm\": [\"mean\", \"std\", \"min\", \"max\"],\n    \"bill_depth_mm\": [\"mean\", \"std\", \"min\", \"max\"],\n    \"sex\": lambda x: x.value_counts().to_dict()  # Count of males and females\n})\n\n# Round numeric values to 1 decimal place (excluding the 'sex' column)\nfor col in summary_table.columns:\n    if summary_table[col].dtype in [float, int]:\n        summary_table[col] = summary_table[col].round(1)\n\n# Display the result\ndisplay(summary_table)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">bill_length_mm</th>\n      <th colspan=\"4\" halign=\"left\">bill_depth_mm</th>\n      <th>sex</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>max</th>\n      <th>&lt;lambda&gt;</th>\n    </tr>\n    <tr>\n      <th>species</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Adelie</th>\n      <td>38.8</td>\n      <td>2.7</td>\n      <td>32.1</td>\n      <td>46.0</td>\n      <td>18.3</td>\n      <td>1.2</td>\n      <td>15.5</td>\n      <td>21.5</td>\n      <td>{'Male': 73, 'Female': 73}</td>\n    </tr>\n    <tr>\n      <th>Chinstrap</th>\n      <td>48.8</td>\n      <td>3.3</td>\n      <td>40.9</td>\n      <td>58.0</td>\n      <td>18.4</td>\n      <td>1.1</td>\n      <td>16.4</td>\n      <td>20.8</td>\n      <td>{'Female': 34, 'Male': 34}</td>\n    </tr>\n    <tr>\n      <th>Gentoo</th>\n      <td>47.6</td>\n      <td>3.1</td>\n      <td>40.9</td>\n      <td>59.6</td>\n      <td>15.0</td>\n      <td>1.0</td>\n      <td>13.1</td>\n      <td>17.3</td>\n      <td>{'Male': 61, 'Female': 58}</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n<aside class=\"notes\">\n\nWe're using the penguins dataset from the seaborn package, so we can use the load_dataset function to get that. We can also drop any na values with the .dropna() method. \n\nWe can then make a quick summary table for the dataset using some of the methods covered last session. \n\n</aside>\n\n## Data Visualization\n\n<div class=\"small-clean-text\"> \n\nTo do visualization, we can use either seaborn or plotnine. `plotnine` mirrors `ggplot2` syntax from R and is great for layered grammar-of-graphics plots, while `seaborn` is more convienient if you want to put multiple plots on the same figure. <br>\n\n\n### Plotting with Plotnine vs Seaborn\n\n::: columns\n::: column\n\n<span style=\"color: #007acc; font-weight: 600;\">Plotnine (like ggplot2 in R)</span><br>\nThe biggest differences between `plotnine` and `ggplot2` syntax are: \n<ul> \n<li> With `plotnine` the whole call is wrapped in `()` parentheses</li>  \n<li> Variables are called with strings (`\"\"` are needed!) </li>\n<li> If you don't use `from plotnine import *`, you will need to import each individual function you plan to use!</li>\n</ul>\n\n:::\n\n::: column\n\n<span  style=\"color: #007acc; font-weight: 600;\">Seaborn (base matplotlib + enhancements)</span><br>\n<ul>\n<li> Designed for **quick, polished plots** </li> \n<li> Works well with **pandas DataFrames** or **NumPy arrays** </li> \n<li> Integrates with `matplotlib` for customization </li> \n<li> Good for things like **decision boundaries** or **heatmaps**</li> \n<li> Harder to customize than plotnine plots </li> \n</ul>\n\n:::\n:::\n\n</div>\n\n<aside class=\"notes\">\n\nTo visually check out our data, we can use either plotnine (which is designed to work like ggplot) or seaborn (base matplotlib + enhancements). \nFor single plots, plotnine can be more convenient but seaborn has better support for putting multiple plots on the same figure. \n\n</aside>\n\n## Scatterplot with plotnine\n<div class=\"clean-text\"> \n\nTo take a look at the distribution of our species by bill length and bill depth before clustering...\n</div>\n\n::: {#fdcdafb0 .cell fig-dpi='600' output-location='fragment' execution_count=19}\n``` {.python .cell-code}\nplot1 = (ggplot(penguins, aes(x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\"))\n + geom_point()\n + ggtitle(\"Penguin Species\")\n + theme_bw())\n\ndisplay(plot1)\n```\n\n::: {.cell-output .cell-output-display}\n![](session4v2_slides_files/figure-revealjs/cell-20-output-1.png){width=960 height=480}\n:::\n:::\n\n\n<aside class=\"notes\">\n\nTo plot our bill length and depth with plotnine, we can pretty much use ggplot syntax, but wrap the whole statement in parentheses. However, our variable names need to be entered as strings. \n\n</aside>\n\n## Scatterplot with seaborn\n\nWe can make a similar plot in seaborn. This time, let's include sex by setting the point style\n\n::: {#3da94f75 .cell output-location='slide' execution_count=20}\n``` {.python .cell-code code-line-numbers=\"1-2|4-12|14-18|20-21\"}\n# Create the figure and axes obects\nfig, ax = plt.subplots(figsize=(10, 8))\n\n# Create a plot \nsns.scatterplot(\n    data=penguins, x=\"bill_length_mm\", y=\"bill_depth_mm\",\n    hue=\"species\", ## hue = fill\n    style=\"sex\",  ## style = style of dots\n    palette=\"Set2\", ## sets color pallet\n    edgecolor=\"black\", s=300, ## line color and point size \n    ax=ax              ## Draw plot on ax      \n)\n\n# Use methods on ax to set title, labels\nax.set_title(\"Penguin Bill Length vs Depth by Species\")\nax.set_xlabel(\"Bill Length (mm)\")\nax.set_ylabel(\"Bill Depth (mm)\")\nax.legend(title=\"Species\")\n\n# Plot the figure\nfig.tight_layout() \n```\n\n::: {.cell-output .cell-output-display}\n![](session4v2_slides_files/figure-revealjs/cell-21-output-1.png){width=949 height=756}\n:::\n:::\n\n\n<aside class=\"notes\">\n\nIf we want to do the same thing in seaborn, we can use sns.scatterplot() directly (which doesn't save the figure to a variable), \nor we can create figure and axis objects first and then draw the plot on the created axis. We then use methods on the axis object to set the titles and labels. \n\nTo display the figure, we can use the .tight_layout() method. \n\n</aside>\n\n\n## Scaling the data - Understanding the Standard Scaler class\n<div class=\"clean-text\">  \n\nFor our clustering to work well, the predictors should be on the same scale. To achieve this, we use an instance of the `StandardScaler` class. \n\n```python\nclass sklearn.preprocessing.StandardScaler(*, copy=True, with_mean=True, with_std=True)\n```\n</div>\n. . .   \n\n**Parameters** are supplied by user  \n- *copy*, *with_mean*, *with_std* <br>\n\n**Attributes** contain the `data` of the object  \n- `scale_`: scaling factor  \n- `mean_`: mean value for each feature  \n- `var_`: variance for each feature  \n- `n_features_in_`: number of features seen during fit  \n- `n_samples_seen`: number of samples processed for each feature <br>\n\n**Methods** describe the `behaviors` of the object and/or `modify` its attributes  \n- `fit(X)`: computes mean and std used for scaling and 'fits' scaler to data X  \n- `transform(X)`: performs standardization by centering and scaling X with fitted scaler  \n- `fit_transform(X)`: does both\n\n<aside class=\"notes\">\n\nFor our clustering to work well, we typically want to put all of the predictors on the same scale. We can do this using an instance of the StandardScaler class. \n\nWe supply the parameters that dictate the behavior of the scaler at instantiation. The new scaler object has attributes that contain the information the object needs to perform its functions, like the scaling factor, feature means and variances, etc. \n\nIt also has methods that can modify its attributes, like the fit method, which calculates the mean and variance used for scaling based on data X, and the tranform method which uses the calculated values to scale X. \n\nFor convenience there is also the fit_transform() method that does both to the same data. When we look at our model classes, we'll see that they also have fit methods. \n\n</aside>\n\n## Scaling Data\n\n<div class=\"clean-text\">  \n\n::: {#493bc7be .cell execution_count=21}\n``` {.python .cell-code code-line-numbers=\"|5-7\"}\n# Selecting features for clustering -> let's just use bill length and bill depth.\nX = penguins[[\"bill_length_mm\", \"bill_depth_mm\"]]\ny = penguins[\"species\"]\n\n# Standardizing the features for better clustering performance\nscaler = StandardScaler() ## create instance of StandardScaler\nX_scaled = scaler.fit_transform(X) \n```\n:::\n\n\n:::{.fragment}\n\n::: {#de204ada .cell execution_count=22}\n\n::: {.cell-output .cell-output-display execution_count=92}\n```{=html}\n<div id=\"huwdtsqvif\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>\n#huwdtsqvif table {\n          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n          -webkit-font-smoothing: antialiased;\n          -moz-osx-font-smoothing: grayscale;\n        }\n\n#huwdtsqvif thead, tbody, tfoot, tr, td, th { border-style: none; }\n tr { background-color: transparent; }\n#huwdtsqvif p { margin: 0; padding: 0; }\n #huwdtsqvif .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }\n #huwdtsqvif .gt_caption { padding-top: 4px; padding-bottom: 4px; }\n #huwdtsqvif .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }\n #huwdtsqvif .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }\n #huwdtsqvif .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #huwdtsqvif .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #huwdtsqvif .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #huwdtsqvif .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }\n #huwdtsqvif .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }\n #huwdtsqvif .gt_column_spanner_outer:first-child { padding-left: 0; }\n #huwdtsqvif .gt_column_spanner_outer:last-child { padding-right: 0; }\n #huwdtsqvif .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }\n #huwdtsqvif .gt_spanner_row { border-bottom-style: hidden; }\n #huwdtsqvif .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }\n #huwdtsqvif .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }\n #huwdtsqvif .gt_from_md> :first-child { margin-top: 0; }\n #huwdtsqvif .gt_from_md> :last-child { margin-bottom: 0; }\n #huwdtsqvif .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }\n #huwdtsqvif .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }\n #huwdtsqvif .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }\n #huwdtsqvif .gt_row_group_first td { border-top-width: 2px; }\n #huwdtsqvif .gt_row_group_first th { border-top-width: 2px; }\n #huwdtsqvif .gt_striped { background-color: rgba(128,128,128,0.05); }\n #huwdtsqvif .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #huwdtsqvif .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }\n #huwdtsqvif .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }\n #huwdtsqvif .gt_left { text-align: left; }\n #huwdtsqvif .gt_center { text-align: center; }\n #huwdtsqvif .gt_right { text-align: right; font-variant-numeric: tabular-nums; }\n #huwdtsqvif .gt_font_normal { font-weight: normal; }\n #huwdtsqvif .gt_font_bold { font-weight: bold; }\n #huwdtsqvif .gt_font_italic { font-style: italic; }\n #huwdtsqvif .gt_super { font-size: 65%; }\n #huwdtsqvif .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }\n #huwdtsqvif .gt_asterisk { font-size: 100%; vertical-align: 0; }\n \n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n<thead>\n\n  <tr class=\"gt_heading\">\n    <td colspan=\"5\" class=\"gt_heading gt_title gt_font_normal\">Original vs Scaled Features</td>\n  </tr>\n<tr class=\"gt_col_headings gt_spanner_row\">\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"2\" colspan=\"1\" scope=\"col\" id=\"Feature\">Feature</th>\n  <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"2\" scope=\"colgroup\" id=\"Original\">\n    <span class=\"gt_column_spanner\">Original</span>\n  </th>\n  <th class=\"gt_center gt_columns_top_border gt_column_spanner_outer\" rowspan=\"1\" colspan=\"2\" scope=\"colgroup\" id=\"Scaled\">\n    <span class=\"gt_column_spanner\">Scaled</span>\n  </th>\n</tr>\n<tr class=\"gt_col_headings\">\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Bill Length\">Bill Length</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Bill Depth\">Bill Depth</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Bill Length\">Bill Length</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Bill Depth\">Bill Depth</th>\n</tr>\n</thead>\n<tbody class=\"gt_table_body\">\n  <tr>\n    <td class=\"gt_row gt_left\">mean</td>\n    <td class=\"gt_row gt_right\">44</td>\n    <td class=\"gt_row gt_right\">17</td>\n    <td class=\"gt_row gt_right\">0</td>\n    <td class=\"gt_row gt_right\">0</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">std</td>\n    <td class=\"gt_row gt_right\">5</td>\n    <td class=\"gt_row gt_right\">2</td>\n    <td class=\"gt_row gt_right\">1</td>\n    <td class=\"gt_row gt_right\">1</td>\n  </tr>\n</tbody>\n\n\n</table>\n\n</div>\n        \n```\n:::\n:::\n\n\n::: {#62ab47b5 .cell execution_count=23}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show table code\"}\n## Make X_scaled a pandas df\nX_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n\n# Compute summary statistics and round to 2 sig figs\noriginal_stats = X.agg([\"mean\", \"std\"])\nscaled_stats = X_scaled_df.agg([\"mean\", \"std\"])\n\n# Combine into a single table with renamed columns\nsummary_table = pd.concat([original_stats, scaled_stats], axis=1)\nsummary_table.columns = [\"Bill_Length_o\", \"Bill_Depth_o\", \"Bill_Length_s\", \"Bill_Depth_s\"]\nsummary_table.index.name = \"Feature\"\n\n# Display nicely with great_tables\n(\n    GT(summary_table.reset_index()).tab_header(\"Original vs Scaled Features\")\n    .fmt_number(columns =  [\"Bill_Length_o\", \"Bill_Depth_o\", \"Bill_Length_s\", \"Bill_Depth_s\"], decimals=0)\n    .tab_spanner(label=\"Original\", columns=[\"Bill_Length_o\", \"Bill_Depth_o\"])\n    .tab_spanner(label=\"Scaled\", columns=[\"Bill_Length_s\", \"Bill_Depth_s\"])\n    .cols_label(Bill_Length_o = \"Bill Length\", Bill_Depth_o = \"Bill Depth\", Bill_Length_s = \"Bill Length\", Bill_Depth_s = \"Bill Depth\")\n    .tab_options(table_font_size = 16)\n)\n```\n:::\n\n\n:::\n\n</div>\n\n<aside class=\"notes\">\n\nTo keep things simple, we will just subset the penguins dataset and keep only bill length and depth for our X dataframe. For y, we'll grab the species as a pandas series. \n\nThe next step is to create the scaler object and use fit_transform to both fit the scaler to X and return the transformed X matrix. One of the nice things about using a scaler object rather than a function is that the object saves the scaling parameters so we can reuse them later. \n\nThis table here just shows how the mean and standard deviation change between the original and scaled features. It was made with great_tables and the code is included below. \n</aside>\n\n## Understanding the KMeans model class\n<div class=\"clean-text\"> \n\n```python\nclass sklearn.cluster.KMeans(n_clusters=8, *, init='k-means++', n_init='auto', max_iter=300, \ntol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n```\n\n**Parameters**: Set by user at time of instantiation  \n- n_clusters, max_iter, algorithm  <br>\n\n**Attributes**: Store object data    \n- `cluster_centers_`: stores coordinates of cluster centers  \n- `labels_`: stores labels of each point \n- `n_iter_`: number of iterations run (will be changed during method run)  \n- `n_features_in` and `feature_names_in_`: store info about features seen during fit  <br>\n\n**Methods**: Define object behaviors      \n- `fit(X)`: fits model to data X\n- `predict(X)`: predicts closest cluster each sample in X belongs to  \n- `transform(X)`: transforms X to cluster-distance space  \n</div>\n\n<aside class=\"notes\">\n\nNow that we have our scaled data, the next step is to create and fit the kmeans model. Like the standardScaler class earlier, we have parameters set by the user. This is where we would specify the number of clusters we want, etc. \n\nThere are also attributes that store information like the location of cluster centers and the cluster labels associated with each point. These attributes are set by the fit method and wont exist for a model that has not been fit yet.\n\nAnd we have the fit and tranasform methods like the scaler class. We also get a predict method that lets us predict cluster labels for any new input data in the same cluster-space. \n\n</aside>\n\n---\n\n<div class=\"clean-text\"> \n\n### Create model\n\n::: {#78a11acd .cell execution_count=24}\n``` {.python .cell-code}\n## Choosing 3 clusters b/c we have 3 species\nkmeans = KMeans(n_clusters=3, random_state=42) ## make an instance of the K means class\nkmeans\n```\n\n::: {.cell-output .cell-output-display execution_count=93}\n```{=html}\n<style>#sk-container-id-7 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-7 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-7 pre {\n  padding: 0;\n}\n\n#sk-container-id-7 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-7 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-7 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-7 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-7 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-7 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-7 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-7 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-7 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-7 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-7 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-7 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-7 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"‚ñ∏\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-7 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-7 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-7 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"‚ñæ\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n#sk-container-id-7 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-7 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-7 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-7 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-7 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-7 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-7 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-7 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-7 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-7 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;KMeans<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>KMeans(n_clusters=3, random_state=42)</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\n<br>\n\n### Fit model to data\n\n::: {#d8f7c1a7 .cell output-location='fragment' execution_count=25}\n``` {.python .cell-code}\n## the fit\npenguins[\"kmeans_cluster\"] = kmeans.fit_predict(X_scaled)\n\n## now that we fit the model, we should have cluster centers\nprint(\"Coordinates of cluster centers:\", kmeans.cluster_centers_)\n\n## shows that model is fitted\nkmeans\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCoordinates of cluster centers: [[-0.95023997  0.55393493]\n [ 0.58644397 -1.09805504]\n [ 1.0886843   0.79503579]]\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=94}\n```{=html}\n<style>#sk-container-id-8 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-8 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-8 pre {\n  padding: 0;\n}\n\n#sk-container-id-8 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-8 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-8 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-8 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-8 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-8 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-8 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-8 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-8 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-8 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-8 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-8 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-8 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"‚ñ∏\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-8 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-8 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-8 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"‚ñæ\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n#sk-container-id-8 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-8 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-8 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-8 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-8 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-8 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-8 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-8 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-8 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-8 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KMeans<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=3, random_state=42)</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\n</div>\n\n<aside class=\"notes\">\n\nNow we create our model, setting the number of clusters to 3 because we have 3 species. One of the fun things about sklearn is that, the repr method gives us this cute little block representation of our model. It shows the parameters that we set during instantiation as well as the model status (the i icon) and link to the model documentation (the ? icon).\nFor non-fitted models, the box is orange and, once we fit the model, the box will be blue!\n\nWe can use the fit-predict method to fit the model to X_scaled and return the cluster labels, which we can store in the penguins dataframe as 'kmeans_cluster'.\n\nNow that the model has been fit, we can check out the cluster centers (remember that this is in scaled X space) and also look at our model representation again to see that it's turned blue. \n\n</aside>\n\n## Use function to calculate ARI\n<div class=\"clean-text\"> \n\nTo check how good our model is, we can use one of the functions included in the sklearn library.\n\nThe `adjusted_rand_score()` function evaluates how well the cluster groupings agree with the species groupings while adjusting for chance. \n\n::: {#1b6d888c .cell output-location='fragment' execution_count=26}\n``` {.python .cell-code}\n# Calculate clustering performance using Adjusted Rand Index (ARI)\nkmeans_ari = adjusted_rand_score(penguins['species'], penguins[\"kmeans_cluster\"])\nprint(f\"k-Means Adjusted Rand Index: {kmeans_ari:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nk-Means Adjusted Rand Index: 0.82\n```\n:::\n:::\n\n\n</div>\n\n<aside class=\"notes\">\n\nSo far, we've mostly used methods in our analysis, but for things that are not model-specific, functions can be useful! We can use the adjusted_rand_score() function to evaluate how well the cluster groupings agree with the species groupings. \n\nSince this function just needs the 'true' labels and the cluster labels, with no actual model information, it makes sense for it to be a function and not a method. \n\n</aside>\n\n---\n\n### We can also use methods on our data structure to create new data\n\n<div class=\"clean-text\"> \n- We can use the `.groupby()` method to help us plot cluster agreement with species label as a heatmap\n- If we want to add sex as a variable to see if that is why our clusters don't agree with our species, we can use a scatterplot\n- Using seaborn and matplotlib, we can easily put both of these plots on the same figure. \n<br>\n\n::: {#0ea46052 .cell execution_count=27}\n``` {.python .cell-code code-line-numbers=\"1-6|8-14|16-17\"}\n# Count occurrences of each species-cluster-sex combination\n# (.size gives the count as index, use reset_index to get count column.)\nscatter_data = (penguins.groupby([\"species\", \"kmeans_cluster\", \"sex\"])\n                .size()\n                .reset_index(name=\"count\"))\nspecies_order = list(scatter_data['species'].unique()) ## defining this for later\n\n# Create a mapping to add horizontal jitter for each sex for scatterplot\nsex_jitter = {'Male': -0.1, 'Female': 0.1}\nscatter_data['x_jittered'] = scatter_data.apply(\n    lambda row: scatter_data['species'].unique().tolist().index(row['species']) +\n     sex_jitter.get(row['sex'], 0),\n    axis=1\n)\n\nheatmap_data = scatter_data.pivot_table(index=\"kmeans_cluster\", columns=\"species\", \nvalues=\"count\", aggfunc=\"sum\", fill_value=0)\n```\n:::\n\n\n</div>\n\n<aside class=\"notes\">\n\nIf we want to visualize the cluster agreement, we can group the data by species, cluster and sex and use the .size() method to get the number of penguins in each 'group'. This yields long-form data that is good for scatterplots. \n\nAs far as I know, there isn't an attached method for horizontal jitter for seaborn, so we can add the jitter manually to separate the 'male' and 'female' points slightly for our scatterplot. \n\nFinally, we can use the .pivot_table method to generate the count data for the heatmap as wide-form data. \n\n</aside>\n\n## Scatter data & Heatmap Data\n\n::: {#74338220 .cell execution_count=28}\n``` {.python .cell-code}\ndisplay(scatter_data.head(3))\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>species</th>\n      <th>kmeans_cluster</th>\n      <th>sex</th>\n      <th>count</th>\n      <th>x_jittered</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Adelie</td>\n      <td>0</td>\n      <td>Female</td>\n      <td>73</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Adelie</td>\n      <td>0</td>\n      <td>Male</td>\n      <td>69</td>\n      <td>-0.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Adelie</td>\n      <td>2</td>\n      <td>Male</td>\n      <td>4</td>\n      <td>-0.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#388baf6a .cell execution_count=29}\n``` {.python .cell-code}\ndisplay(heatmap_data)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>species</th>\n      <th>Adelie</th>\n      <th>Chinstrap</th>\n      <th>Gentoo</th>\n    </tr>\n    <tr>\n      <th>kmeans_cluster</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>142</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>9</td>\n      <td>112</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>54</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n<aside class=\"notes\">\nAfter the transformations we performed, this is what our scatter data and heatmap data look like. \n</aside>\n\n## Creating Plots \n\n::: {#2e588b71 .cell output-location='slide' execution_count=30}\n``` {.python .cell-code code-line-numbers=\"1-2|4-9|11-23\"}\n# Prepare the figure with 2 subplots; the axes object will contain both plots\nfig2, axes = plt.subplots(1, 2, figsize=(16, 7)) ## 1 row 2 columns\n\n# Plot heatmap on the first axis\nsns.heatmap(data = heatmap_data, cmap=\"Blues\", linewidths=0.5, linecolor='white', annot=True, \nfmt='d', ax=axes[0]) ## fmt='d' = decimal (base10) integer, use fmt='f' for floats \naxes[0].set_title(\"Heatmap of KMeans Clustering by Species\")\naxes[0].set_xlabel(\"Species\")\naxes[0].set_ylabel(\"KMeans Cluster\")\n\n# Scatterplot with jitter\nsns.scatterplot(data=scatter_data, x=\"x_jittered\", y=\"kmeans_cluster\",\n    hue=\"species\", style=\"sex\", size=\"count\", sizes=(100, 500),\n    alpha=0.8, ax=axes[1], legend=\"brief\")\naxes[1].set_xticks(range(len(species_order)))\naxes[1].set_xticklabels(species_order)\naxes[1].set_title(\"Cluster Assignment by Species and Sex (Jittered)\")\naxes[1].set_ylabel(\"KMeans Cluster\")\naxes[1].set_xlabel(\"Species\")\naxes[1].set_yticks([0, 1, 2])\naxes[1].legend(bbox_to_anchor=(1.05, 0.5), loc='center left', borderaxespad=0.0, title=\"Legend\")\n\nfig2.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](session4v2_slides_files/figure-revealjs/cell-31-output-1.png){width=1530 height=660}\n:::\n:::\n\n\n<aside class=\"notes\">\nNow we can create our plots on this new figure, fig2. Because we want to create more than 1 plot, we have additional arguments in plt.subplots. 1, 2 means 1 row 2 columns. \n\nThis time, our 'axis' is actually a 1d array of axis objects. If we had more than 1 row, it would be a 2d array (like a matrix). **-adv-** \nIf we want to plot the heatmap on the first 'ax', we can set ax=axes[0]. Here, we don't have to explicitly set X and Y, we can just pass the data into the heatmap function.\n\n**-adv-** For our scatterplot, we need to set x and y explicitly, using the x_jittered column so our points don't overlap. \nTo make things clean here, we can set the xticks using the species_order we defined previously and put our legend to the left of the plot.\n\nfinally, to display the completed figure, we use fig2.tight_layout()\n\nNote: bbox_to_anchor -> x coord, y coord in terms of plot size. Aka a little more than 1 plot to the left and half a plot up. \n\n\n</aside>\n\n## Project 2: KNN classification\n\n<div class=\"clean-text\"> \n\nFor our KNN classification, the model is **supervised** (meaning it is dependent on the outcome 'y' data). This time, we need to split our data into a training and test set. <br>\n\n</div>\n\n. . . \n\nThe **function** `train_test_split()` from scikit-learn is helpful here! \n\n::: {#2aa2d4d7 .cell execution_count=31}\n``` {.python .cell-code}\n# Splitting dataset into training and testing sets (still using scaled X!)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n```\n:::\n\n\n. . . \n\n>Unlike R functions, which return a single object (often a list when multiple outputs are needed), Python functions can return multiple values as a tuple‚Äîletting you unpack them directly into separate variables.\n\n<aside class=\"notes\">\nNow we can move on to our KNN classification. Because this model is supervised, it is dependent on the species data. To have a meaningful model, we need to split our data into a training and test set, \nwhich we can do using the function `train_test_split()`. We are still using the scaled X from before, but we want to reserve 30% of our data for testing. \n\nWe can assign the outputs directly to different variables. \n\n(help(train_test_split) will show what the output order is)\n</aside>\n\n## Understanding KNeighborsClassifier class\n\n```{.python}\nclass sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', \nalgorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n```\n. . . \n\n**Parameters**: Set by user at time of instantiation    \n- n_neigbors, weights, algorithm, etc.  <br>\n\n**Attributes**: Store object data     \n- `classes_`: class labels known to the classifier  \n- `effective_metric_`: distance metric used  \n- `effective_metric_params_`: parameters for the metric function  \n- `n_features_in` and `feature_names_in_`: store info about features seen during fit    \n- `n_samples_fit_`: number of samples in fitted data  <br> \n\n**Methods**: Define object behaviors      \n- `.fit(X, y)`: fit knn classifier from training dataset (X and y)  \n- `.predict(X)`: predict class labels for provided data X  \n- `.predict_proba(X)`: return probability estimates for test data X  \n- `.score(X, y)`: return mean accuracy on given test data X and labels y  \n\n<aside class=\"notes\">\nThe KNeighbors classifier class is similar to the kmeans class, with a notable difference. The fit method here requires both X and y. \nTechnically, the fit method in kmeans can accept a y value, it just won't use it. This is done to allow for interchangable models in pipelines. \n\nThe neighbors classifier also lacks the transform method because it doesn't create a 'space' like the kmeans cluster-distance space. \nInstead, it has the .predict_proba method, which gives class probability estimates for input data. \n\n</aside>\n\n## Making an instance of KNeighborsClassifier and fitting to training data\n- For a supervised model, y_train is included in `.fit()`!\n\n::: {#6c4a8686 .cell execution_count=32}\n``` {.python .cell-code}\n## perform knn classification\n# Applying k-NN classification with 5 neighbors\nknn = KNeighborsClassifier(n_neighbors=5) ## make an instance of the KNeighborsClassifier class\n# and set the n_neighbors parameter to be 5. \n\n# Use the fit method to fit the model to the training data\nknn.fit(X_train, y_train)\nknn\n```\n\n::: {.cell-output .cell-output-display execution_count=101}\n```{=html}\n<style>#sk-container-id-9 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-9 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-9 pre {\n  padding: 0;\n}\n\n#sk-container-id-9 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-9 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-9 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-9 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-9 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-9 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-9 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-9 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-9 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-9 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-9 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-9 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-9 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"‚ñ∏\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-9 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-9 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-9 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"‚ñæ\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n#sk-container-id-9 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-9 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-9 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-9 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-9 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-9 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-9 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-9 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-9 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-9 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier()</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\n<aside class=\"notes\">\nFitting the knn model works the same as fitting the kmeans model, except we have to supply the 'y' values. \n</aside>\n\n## Once the model is fit...\n\n-We can look at its attributes (ex: `.classes_`) which gives the class labels as known to the classifier\n\n::: {#99aeb63b .cell output-location='fragment' execution_count=33}\n``` {.python .cell-code}\nprint(knn.classes_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['Adelie' 'Chinstrap' 'Gentoo']\n```\n:::\n:::\n\n\n. . . \n\n-And use fitted model to predict species for test data\n\n::: {#b0c776e4 .cell output-location='fragment' execution_count=34}\n``` {.python .cell-code}\n# Use the predict method on the test data to get the predictions for the test data\ny_pred = knn.predict(X_test)\n\n# Also can take a look at the prediction probabilities, \n# and use the .classes_ attribute to put the column labels in the right order\nprobs = pd.DataFrame(\n    knn.predict_proba(X_test),\n    columns = knn.classes_)\nprobs['y_pred'] = y_pred\n\nprint(\"Predicted probabilities: \\n\", probs.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPredicted probabilities: \n    Adelie  Chinstrap  Gentoo     y_pred\n0     1.0        0.0     0.0     Adelie\n1     0.0        0.0     1.0     Gentoo\n2     1.0        0.0     0.0     Adelie\n3     0.0        0.6     0.4  Chinstrap\n4     1.0        0.0     0.0     Adelie\n```\n:::\n:::\n\n\n<aside class=\"notes\">\nAfter fitting, we can see that the classifier has learned the labels from the dataset, and we are able to use it to predict species labels for the test data. \n\nWe use the .predict method to get the predicted classes and the .predict proba method to get the actual probabilities. \nWe can store both of these in a pandas dataframe, which we can use to make a scatterplot to compare the actual and predicted classes. \n</aside>\n\n## Scatterplot for k-NN classification of test data\n\n<div class=\"clean-text\"> \n\n- Create dataframe of unscaled X_test, `bill_length_mm`, and `bill_depth_mm`.\n- Add to it the actual and predicted species labels\n\n::: {#09d391f1 .cell output-location='fragment' execution_count=35}\n``` {.python .cell-code}\n## First unscale the test data\nX_test_unscaled = scaler.inverse_transform(X_test)\n\n## create dataframe \npenguins_test = pd.DataFrame(\n    X_test_unscaled,\n    columns=['bill_length_mm', 'bill_depth_mm']\n)\n\n## add actual and predicted species \npenguins_test['y_actual'] = y_test.values\npenguins_test['y_pred'] = y_pred\npenguins_test['correct'] = penguins_test['y_actual'] == penguins_test['y_pred']\n\nprint(\"Results: \\n\", penguins_test.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResults: \n    bill_length_mm  bill_depth_mm   y_actual     y_pred  correct\n0            39.5           16.7     Adelie     Adelie     True\n1            46.9           14.6     Gentoo     Gentoo     True\n2            42.1           19.1     Adelie     Adelie     True\n3            49.8           17.3  Chinstrap  Chinstrap     True\n4            41.1           18.2     Adelie     Adelie     True\n```\n:::\n:::\n\n\n<aside class=\"notes\">\nUsing the scaler object we created previously, we can un-scale the test data and create a new dataframe that contains the unscaled predictors as well as the true and predicted species. \n\nLine 13 here creates a boolean (true/false) column for agreement between the actual and predicted species. \n</aside>\n\n</div>\n\n## Plotnine scatterplot for k-NN classification of test data\n\nTo see how well our model did at classifying the remaining penguins...\n\n::: {#55104782 .cell output-location='slide' execution_count=36}\n``` {.python .cell-code}\n## Build the plot\nplot3 = (ggplot(penguins_test, aes(x=\"bill_length_mm\", y=\"bill_depth_mm\", \ncolor=\"y_actual\", fill = 'y_pred', shape = 'correct'))\n + geom_point(size=4, stroke=1.1)  # Stroke controls outline thickness\n + scale_shape_manual(values={True: 'o', False: '^'})  # Circle and triangle\n + ggtitle(\"k-NN Classification Results\")\n + theme_bw())\n\ndisplay(plot3)\n```\n\n::: {.cell-output .cell-output-display}\n![](session4v2_slides_files/figure-revealjs/cell-37-output-1.png){width=960 height=480}\n:::\n:::\n\n\n<aside class=\"notes\">\nNow we can put all of this together into a plot. This plot is overely complicated, but I wanted to use it to show some more of the plot options in plotnine. \n</aside>\n\n## Visualizing Decision Boundary with seaborn and matplotlib\n\n::: {#eb621fb9 .cell output-location='slide' execution_count=37}\n``` {.python .cell-code code-line-numbers=\"1-6|8-22|24-27|\"}\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.preprocessing import LabelEncoder\n\n# Create and fit label encoder for y (just makes y numeric because it makes the scatter plot happy)\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Create the plot objects\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Create display object\ndisp = DecisionBoundaryDisplay.from_estimator(\n    knn,\n    X_test,\n    response_method = 'predict',\n    plot_method = 'pcolormesh',\n    xlabel = \"bill_length_scaled\",\n    ylabel = \"bill_depth_scaled\",\n    shading = 'auto',\n    alpha = 0.5,\n    ax = ax\n)\n\n# Use method from display object to create scatter plot\nscatter = disp.ax_.scatter(X_scaled[:,0], X_scaled[:,1], c=y_encoded, edgecolors = 'k')\ndisp.ax_.legend(scatter.legend_elements()[0], knn.classes_, loc = 'lower left', title = 'Species')\n_ = disp.ax_.set_title(\"Penguin Classification\")\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](session4v2_slides_files/figure-revealjs/cell-38-output-1.png){width=959 height=671}\n:::\n:::\n\n\n<aside class=\"notes\">\nTo visualize the decision boundary of the modelm we can use another sklearn class called DecisionBoundaryDisplay, \nwhich creates a display object that has matplotlib-style plotting methods. \nWe assign our axis in the creation of our display object and use the attached .ax_. methods to create the scatter plot and legend as well as set the title. \n\nInstead of using fig.tight_layout() we can use plt.show() since the plot we want to display is the current queued plot. \n\n</aside>\n\n\n## Evaluate KNN performance\n\n<div class=\"clean-text\"> \nTo check the performance of our KNN classifier, we can check the accuracy score and print a classification report.  \n- `accuracy_score` and `classification_report` are both functions!  \n- They are not unique to scikit-learn classes so it makes sense for them to be functions not methods  \n\n</div> \n\n::: {#dab75f38 .cell output-location='fragment' execution_count=38}\n``` {.python .cell-code}\n## eval knn performance\nknn_accuracy = accuracy_score(y_test, y_pred)\nprint(f\"k-NN Accuracy: {knn_accuracy:.2f}\")\nprint(\"Classification Report: \\n\", classification_report(y_test, y_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nk-NN Accuracy: 0.94\nClassification Report: \n               precision    recall  f1-score   support\n\n      Adelie       0.98      0.98      0.98        48\n   Chinstrap       0.80      0.89      0.84        18\n      Gentoo       0.97      0.91      0.94        34\n\n    accuracy                           0.94       100\n   macro avg       0.92      0.93      0.92       100\nweighted avg       0.94      0.94      0.94       100\n\n```\n:::\n:::\n\n\n## Make a Summary Table of Metrics for Both Models\n\n::: {#d3d8b5de .cell output-location='fragment' execution_count=39}\n``` {.python .cell-code}\nsummary_table = pd.DataFrame({\n    \"Metric\": [\"k-Means Adjusted Rand Index\", \"k-NN Accuracy\"],\n    \"Value\": [kmeans_ari, knn_accuracy]\n})\n(\n    GT(summary_table)\n    .tab_header(title = \"Model Results Summary\")\n    .fmt_number(columns = \"Value\", n_sigfig = 2)\n    .tab_options(table_font_size = 20)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=108}\n```{=html}\n<div id=\"vfxpvqixey\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>\n#vfxpvqixey table {\n          font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n          -webkit-font-smoothing: antialiased;\n          -moz-osx-font-smoothing: grayscale;\n        }\n\n#vfxpvqixey thead, tbody, tfoot, tr, td, th { border-style: none; }\n tr { background-color: transparent; }\n#vfxpvqixey p { margin: 0; padding: 0; }\n #vfxpvqixey .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 20; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; }\n #vfxpvqixey .gt_caption { padding-top: 4px; padding-bottom: 4px; }\n #vfxpvqixey .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; }\n #vfxpvqixey .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; }\n #vfxpvqixey .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #vfxpvqixey .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #vfxpvqixey .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; }\n #vfxpvqixey .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; }\n #vfxpvqixey .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; }\n #vfxpvqixey .gt_column_spanner_outer:first-child { padding-left: 0; }\n #vfxpvqixey .gt_column_spanner_outer:last-child { padding-right: 0; }\n #vfxpvqixey .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; }\n #vfxpvqixey .gt_spanner_row { border-bottom-style: hidden; }\n #vfxpvqixey .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; }\n #vfxpvqixey .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; }\n #vfxpvqixey .gt_from_md> :first-child { margin-top: 0; }\n #vfxpvqixey .gt_from_md> :last-child { margin-bottom: 0; }\n #vfxpvqixey .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; }\n #vfxpvqixey .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; }\n #vfxpvqixey .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; }\n #vfxpvqixey .gt_row_group_first td { border-top-width: 2px; }\n #vfxpvqixey .gt_row_group_first th { border-top-width: 2px; }\n #vfxpvqixey .gt_striped { background-color: rgba(128,128,128,0.05); }\n #vfxpvqixey .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; }\n #vfxpvqixey .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; }\n #vfxpvqixey .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; text-align: left; }\n #vfxpvqixey .gt_left { text-align: left; }\n #vfxpvqixey .gt_center { text-align: center; }\n #vfxpvqixey .gt_right { text-align: right; font-variant-numeric: tabular-nums; }\n #vfxpvqixey .gt_font_normal { font-weight: normal; }\n #vfxpvqixey .gt_font_bold { font-weight: bold; }\n #vfxpvqixey .gt_font_italic { font-style: italic; }\n #vfxpvqixey .gt_super { font-size: 65%; }\n #vfxpvqixey .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; }\n #vfxpvqixey .gt_asterisk { font-size: 100%; vertical-align: 0; }\n \n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n<thead>\n\n  <tr class=\"gt_heading\">\n    <td colspan=\"2\" class=\"gt_heading gt_title gt_font_normal\">Model Results Summary</td>\n  </tr>\n<tr class=\"gt_col_headings\">\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Metric\">Metric</th>\n  <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Value\">Value</th>\n</tr>\n</thead>\n<tbody class=\"gt_table_body\">\n  <tr>\n    <td class=\"gt_row gt_left\">k-Means Adjusted Rand Index</td>\n    <td class=\"gt_row gt_right\">0.82</td>\n  </tr>\n  <tr>\n    <td class=\"gt_row gt_left\">k-NN Accuracy</td>\n    <td class=\"gt_row gt_right\">0.94</td>\n  </tr>\n</tbody>\n\n\n</table>\n\n</div>\n        \n```\n:::\n:::\n\n\n## Key Takeaways from This Session\n\n<div class=\"clean-text\"> \n<p style=\"font-size: 1.25em\"> \n</p>\n<ul style=\"font-size: 1.1em; margin: 0 auto;\">\n  <li><strong>Python workflows rely on object-oriented structures in addition to functions:</strong><br>\n   Understanding the OOP paradigm makes Python a lot easier!</li>\n  <li><strong>Everything is an object!</strong></li>\n  <li><strong>Duck Typing:</strong><br>\n  If an object has a method, that method can be called regardless of the object type. Caveat being, make sure the arguments (if any) in the method are specified correctly for all objects!\n  </li>\n    <li>Python packages use <strong>common methods</strong> that make it easy to change between model types without changing a lot of code. \n  </li>\n</ul>\n</div>\n\n## Additional Insights\n\n<div class=\"clean-text\" style=\"font-size: 1.0em; line-height: 1.4;\">\n  <ul>\n    <li>\n      <strong>Predictable APIs enable seamless model switching:</strong><br>\n      Swapping models like <code>LogisticRegression</code> ‚Üí <code>RandomForestClassifier</code> usually requires minimal code changes.\n    </li>\n    <li style=\"margin-top: .7em;\">\n      <strong>scikit-learn prioritizes interoperability:</strong><br>\n      Its consistent class design integrates with tools like <code>Pipeline</code>, <code>GridSearchCV</code>, and <code>cross_val_score</code>.\n    </li>\n    <li style=\"margin-top: .7em;\">\n      <strong>Class attributes improve model transparency:</strong><br>\n      Access attributes like <code>.coef_</code>, <code>.classes_</code>, and <code>.feature_importances_</code> for model interpretation and debugging.\n    </li>\n    <li style=\"margin-top: .7em;\">\n      <strong>Custom classes are central to deep learning:</strong><br>\n      Frameworks like PyTorch and TensorFlow require you to define your own model classes by subclassing base models.\n    </li>\n    <li style=\"margin-top: .7em;\">\n      <strong>Mixins support modular design:</strong><br>\n      Mixins (e.g., <code>ClassifierMixin</code>) let you add specific functionality without duplicating code.\n    </li>\n  </ul>\n</div>\n\n## **Pre-Reading for This Session**  \n\n<div class=\"clean-text\">\n\n- [Scikit-learn Documentation](https://scikit-learn.org/stable/user_guide.html)  \n- [Introduction to OOP in Python (Real Python)](https://realpython.com/python3-object-oriented-programming/)  \n- [Plotnine Reference](https://plotnine.org/reference/)\n- [Seaborn Reference](https://seaborn.pydata.org/tutorial/function_overview.html)\n\n</div>\n\n",
    "supporting": [
      "session4v2_slides_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}