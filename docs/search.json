[
  {
    "objectID": "session4_newMLDemo/session4v2.html#session-overview",
    "href": "session4_newMLDemo/session4v2.html#session-overview",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Session Overview",
    "text": "Session Overview\n\n\nIn this session, we‚Äôll explore how Python‚Äôs object-oriented nature affects our modeling workflows.\n\n\n\nTopics:\n\n\n\nIntro to OOP and how it makes modeling in Python different from R\n\n\nBuilding and extending classes using inheritance and mixins\n\n\nApplying OOP to machine learning through demos with scikit-learn"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#introduction",
    "href": "session4_newMLDemo/session4v2.html#introduction",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Introduction",
    "text": "Introduction\nBoth R and python use objects, but not everything in R is object-oriented‚Ä¶ If that sounds confusing that‚Äôs because it is! \nFunctional programming: focuses on functions as the primary unit of code \nObject-oriented programming: uses objects with attached attributes(data) and methods(behaviors) \nFunctional and object-oriented programming are paradigms (styles) and these styles can be applied in both R and Python. However, Python libraries and workflows tend to rely more on object-oriented programming than those designed for R.\n\nR originated from another statistical programming language called S, which is not object-oriented, and R tends to lend itself better to functional programming than object-oriented programming in many cases."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#why-python",
    "href": "session4_newMLDemo/session4v2.html#why-python",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Why Python? üêç",
    "text": "Why Python? üêç\n\n\nR: Built by Statisticians for Statisticians\n\nExcels at:\n\nStatistical analysis and modeling\n\nClean outputs and tables from models\nBeautiful data visualizations with simple code\n\n\n\nPython: General-Purpose Language\n\nExcels at:\n\nMachine Learning, Neural Networks & Deep Learning (scikit-learn, PyTorch, TensorFlow)\n\nImage & Genomic Data Analysis (scikit-image, biopython, scanpy)\nSoftware & Command Line Interfaces, Web Scraping, Automation\n\n\n\nPython‚Äôs broader ecosystem makes it the go-to language in domains like AI, bioinformatics, data engineering, and computational biology.\n\nNote: Packages like rpy2 and reticulate make it possible to use both R and Python in the same project, but those are beyond the scope of this course.\nA primer on reticulate is available here: https://www.r-bloggers.com/2022/04/getting-started-with-python-using-r-and-reticulate/"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#functions-vs-objects-in-python",
    "href": "session4_newMLDemo/session4v2.html#functions-vs-objects-in-python",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Functions vs Objects in Python",
    "text": "Functions vs Objects in Python\n\nPython absolutely uses functions‚Äîjust like R! They‚Äôre helpful for data transformation, wrangling, and automation tasks like looping and parallelization. \nBut when it comes to modeling, libraries are designed around classes: blueprints for creating objects that store data (attributes) and define behaviors (methods). \n\nscikit-learn is great for getting started‚Äîeverything from regression to clustering follows a simple, consistent OOP interface. Its API is also consistant with other python modeling packages, like xgboost for gradient boosting and scvi-tools for transcriptomics data.\nscikit-survival is built off\nPyTorch and TensorFlow are essential if you go deeper into neural networks or custom models‚Äîyou‚Äôll define your own model classes with attributes and methods, but the basic structure is similar to scikit-learn.\n\nstatsmodels is an alternative to scikit-learn for statistical analyses and has R-like syntax and outputs. It‚Äôs a bit more complex than scikit-learn and a bit less consistant with other packages in the python ecosystem.\n\n\nüí° To work effectively in Python, especially for tasks involving modeling or model training, it helps to think in terms of objects and classes, not just functions."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#why-oop-matters-in-python",
    "href": "session4_newMLDemo/session4v2.html#why-oop-matters-in-python",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Why OOP Matters in Python",
    "text": "Why OOP Matters in Python\n\nMany of the most popular Python libraries for modeling‚Äîsuch as scikit-learn, statsmodels, PyTorch, and TensorFlow‚Äîare built around the principles of object-oriented programming (OOP).\nThis means that to work effectively in Python, especially for tasks involving modeling or model training, it helps to think in terms of objects and classes, not just functions. \n\nModels in Python:\n\nTypically instances of classes\nCome with built-in methods (like .fit() or .predict()) and attributes (like .coef_) that define their behavior and internal state"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#why-oop-matters-for-machine-learning-modeling",
    "href": "session4_newMLDemo/session4v2.html#why-oop-matters-for-machine-learning-modeling",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Why OOP Matters for Machine Learning/ Modeling",
    "text": "Why OOP Matters for Machine Learning/ Modeling\n\nIf you‚Äôre doing machine learning, deep learning, or building custom models in Python, you‚Äôre often working in domains where R doesn‚Äôt offer as much built-in support. That‚Äôs where packages like:\n\nscikit-learn (machine learning)\nPyTorch and TensorFlow (deep learning and neural networks)\n\ncome in.\n\n\nScikit-learn provides a wide array of ready-to-use model classes, making it a great entry point\nPyTorch and TensorFlow, especially for custom neural network architectures, require you to create your own classes using inheritance from base classes and mixins\n\nI won‚Äôt go deep into PyTorch or TensorFlow here, but feel free to ask me later or explore tutorials online if you‚Äôre curious!"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#statsmodels",
    "href": "session4_newMLDemo/session4v2.html#statsmodels",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Statsmodels",
    "text": "Statsmodels\n\nStatsmodels offers a more R-like interface for regression models but requires some additional setup for design matrices. (You can check out their excellent documentation here.)\n\nI won‚Äôt cover statsmodels here, but it is worth looking up if you are interested."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#what-well-cover",
    "href": "session4_newMLDemo/session4v2.html#what-well-cover",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "What We‚Äôll Cover",
    "text": "What We‚Äôll Cover\nTo get comfortable with this way of thinking, we‚Äôll first do a brief recap of object-oriented programming‚Äîwhat classes are, how inheritance works, and how you can define your own classes in Python. \nThen we‚Äôll shift focus to using model classes in Python, particularly with scikit-learn. \nWhether you‚Äôre using a prebuilt model class or writing your own from scratch, the workflow is often similar. You‚Äôll still need to use or define common methods like .fit(), .predict(), and .score(), and understand how the model stores internal data like coefficients and hyperparameters."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#recap-what-are-classes-and-objects",
    "href": "session4_newMLDemo/session4v2.html#recap-what-are-classes-and-objects",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Recap: What Are Classes and Objects?",
    "text": "Recap: What Are Classes and Objects?\nA class is a blueprint for creating objects. An object is an instance of a class that contains data (attributes) and behaviors (methods).\nClasses are defined using the class keyword, and their structure is specified using an __init__() method for initialization.\n\nFor example, we can define a class called Dog and give it attributes that store data about a given dog.\nWe can also add methods that represent behaviors an object of the Dog class can perform:\n\n\n\nclass Dog: ## begin class definition\n    def __init__(self, name, breed): ## define init method\n        self.name = name ## add attributes\n        self.breed = breed\n\n    def speak(self): ## add methods\n        return f\"{self.name} says woof!\""
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#creating-a-dog",
    "href": "session4_newMLDemo/session4v2.html#creating-a-dog",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Creating a dog",
    "text": "Creating a dog\nCreating an instance (object) of the Dog class lets us model a particular dog:\n\n\nbuddy = Dog(\"Buddy\", \"Golden Retriever\")\nbuddy ## displays what was in the __repr__() method\n\n\n\nDog(name='Buddy', breed='Golden Retriever')\n\n\n\n\nHere, buddy is an object of the Dog class.\nIt has attributes (name, breed) and methods (speak()).\n\n\nWhen we make an instance of the Dog class:\n- We set the value of the attributes [name and breed], which are then stored as part of the buddy object\n- We can use any methods defined in the Dog class on buddy\n\n## if we want to see what kind of dog our dog is\n## we can call buddy's attributes\nprint(f\"Our dog {buddy.name} is a {buddy.breed}.\")\n\n## we can also call any Dog methods\nprint(buddy.speak())  \n\n\n\nOur dog Buddy is a Golden Retriever.\nBuddy says woof!\n\n\n\n\nNote: For python methods, the self argument is assumed to be passed and therefore we do not put anything in the parentheses when calling .speak()."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#how-does-this-relate-to-machine-learning-and-modeling",
    "href": "session4_newMLDemo/session4v2.html#how-does-this-relate-to-machine-learning-and-modeling",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "How Does This Relate to Machine Learning and Modeling?",
    "text": "How Does This Relate to Machine Learning and Modeling?\n\nMachine learning models in Python are implemented as classes.\n- When you create a model, you‚Äôre instantiating an object of a predefined class (e.g., LogisticRegression()).\n- That model inherits attributes (parameters, coefficients) and methods (like .fit() and .predict())."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#key-benefits-of-oop-in-machine-learning",
    "href": "session4_newMLDemo/session4v2.html#key-benefits-of-oop-in-machine-learning",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Key Benefits of OOP in Machine Learning",
    "text": "Key Benefits of OOP in Machine Learning\n\nEncapsulation ‚Äì Models store parameters and methods inside a single object.\n\nInheritance ‚Äì New models can build on base models, reusing existing functionality.\n\nAbstraction ‚Äì .fit() should work as expected, regardless of complexity of underlying implimentation.\nPolymorphism (Duck Typing) ‚Äì Different models share the same method names (.fit(), .predict()), making them easy to use interchangeably, particularly in analysis pipelines.\n\nUnderstanding base classes and mixins is especially important when working with deep learning frameworks like PyTorch and TensorFlow, as they allow for easy customization of models.\nBy using object-oriented programming, Python makes it easy to structure machine learning workflows in a reusable and scalable way. The fact that all ML models in scikit-learn follow the same structure (with .fit(), .predict(), .score(), etc.) makes it easier to switch between models and automate processes. Additionally, the model classes in the statsmodels package have many of the same methods (.fit(), .predict(), .score())."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#example-understanding-classes---definition-inheritance-mixins",
    "href": "session4_newMLDemo/session4v2.html#example-understanding-classes---definition-inheritance-mixins",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Example: Understanding Classes - Definition, Inheritance, Mixins",
    "text": "Example: Understanding Classes - Definition, Inheritance, Mixins\nBefore we get into the machine learning demo projects, I want to quickly demonstrate how classes work and how we can leverage inheritance when making our own classes.\nEven though this example is very simple, the same method applies to making your own classes for machine learning and neural network models."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#base-classes",
    "href": "session4_newMLDemo/session4v2.html#base-classes",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Base Classes",
    "text": "Base Classes\nA base class (or parent class) serves as a template for creating objects. Other classes can inherit from it to reuse its properties and methods.\nClasses are defined using the class keyword, and their structure is specified using an __init__() method for initialization.\n\nFor example, we can define a class called Dog and give it attributes that store data about a given dog.\nWe can also add methods that represent behaviors an object of the Dog class can perform:\n\n\n\nclass Dog: ## begin class definition\n    def __init__(self, name, breed): ## define init method\n        self.name = name ## add attributes\n        self.breed = breed\n\n    def speak(self): ## add methods\n        return f\"{self.name} says woof!\"\n\n    def __str__(self): ## add special methods, __str__(self) tells python what to display when an object is printed\n        return f\"Our dog {self.name}\"\n\n    def __repr__(self): ## add representation to display when dog is called in console\n        return f\"Dog(name={self.name!r}, breed={self.breed!r})\""
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#derived-child-classes",
    "href": "session4_newMLDemo/session4v2.html#derived-child-classes",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Derived (Child) Classes",
    "text": "Derived (Child) Classes\nDerived/child classes build on base classes using the principle of inheritence. \nNow that we have a Dog class, we can build on it to create a specialized GuardDog class.\n\nclass GuardDog(Dog):  # GuardDog inherits from Dog\n    def __init__(self, name, breed, training_level): ## in addition to name and breed, we can \n        # define a training level. \n        # Call the parent (Dog) class's __init__ method\n        super().__init__(name, breed)\n        self.training_level = training_level  # New attribute for GuardDog that stores the \n        # training level for the dog\n\n    def guard(self): ## checks if the training level is &gt; 5 and if not says train more\n        if self.training_level &gt; 5:\n            return f\"{self.name} is guarding the house!\"\n        else:\n            return f\"{self.name} needs more training before guarding.\"\n    \n    def train(self): ## modifies the training_level attribute to increase the dog's training level\n        self.training_level = self.training_level + 1\n        return f\"Training {self.name}. {self.name}'s training level is now {self.training_level}\"\n\n# Creating an instance of GuardDog\nrex = GuardDog(\"Rex\", \"German Shepherd\", training_level= 5)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#mixins",
    "href": "session4_newMLDemo/session4v2.html#mixins",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Mixins",
    "text": "Mixins\nA mixin is a special kind of class designed to add functionality to another class. Unlike base classes, mixins aren‚Äôt used alone.\n\nFor example, scikit-learn uses mixins like:\n- sklearn.base.ClassifierMixin (adds classifier-specific methods)\n- sklearn.base.RegressorMixin (adds regression-specific methods)\nwhich it adds to the BaseEstimator class to add functionality.\nTo finish up our dog example, we are going to define a mixin class that adds a functionality to the base Dog() class which allows us to teach a dog tricks."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#oop-in-ml-recap",
    "href": "session4_newMLDemo/session4v2.html#oop-in-ml-recap",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "OOP In ML Recap",
    "text": "OOP In ML Recap\nKey Benefits of OOP in Machine Learning\n\nEncapsulation ‚Äì Models store parameters and methods inside a single object.\n\nInheritance ‚Äì New models can build on base models, reusing existing functionality.\n\nAbstraction ‚Äì .fit() should work as expected, regardless of complexity of underlying implimentation.\nPolymorphism (Duck Typing) ‚Äì Different models share the same method names (.fit(), .predict()), making them easy to use interchangeably, particularly in analysis pipelines.\n\nUnderstanding base classes and mixins is especially important when working with deep learning frameworks like PyTorch and TensorFlow, as they allow for easy customization of models.\nBy using object-oriented programming, Python makes it easy to structure machine learning workflows in a reusable and scalable way. The fact that all ML models in scikit-learn follow the same structure (with .fit(), .predict(), .score(), etc.) makes it easier to switch between models and automate processes. Additionally, the model classes in the statsmodels package have many of the same methods (.fit(), .predict(), .score())."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#mini-project-classifying-penguins-with-scikit-learn",
    "href": "session4_newMLDemo/session4v2.html#mini-project-classifying-penguins-with-scikit-learn",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "üêß Mini Project: Classifying Penguins with scikit-learn",
    "text": "üêß Mini Project: Classifying Penguins with scikit-learn\nNow that you understand classes and data structures in Python, let‚Äôs apply that knowledge!\nIn this project, we‚Äôll try to classify penguin species using two features:\n- bill_length_mm\n- bill_depth_mm\nWe‚Äôll explore:\n- Unsupervised learning with K-Means clustering (model doesn‚Äôt ‚Äòknow‚Äô y) - Supervised learning with a k-NN classifier (model trained w/ y information)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#modeling-with-scikit-learn-classes",
    "href": "session4_newMLDemo/session4v2.html#modeling-with-scikit-learn-classes",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Modeling with scikit-learn Classes",
    "text": "Modeling with scikit-learn Classes\nWe‚Äôll use models from scikit-learn, which are built using object-oriented design.\nEach model is an instance of a class (inheriting from BaseEstimator) with:\nCommon Methods:\n- .fit() ‚Äî Train the model\n- .predict() ‚Äî Make predictions\nCommon Attributes:\n- .get_params(), .classes_, .n_clusters_, etc.\n\nWe‚Äôre using scikit-learn here for its simplicity, but the concepts apply to more advanced frameworks like PyTorch and TensorFlow too!"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#general-modeling-workflow",
    "href": "session4_newMLDemo/session4v2.html#general-modeling-workflow",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "General Modeling Workflow",
    "text": "General Modeling Workflow\n\n\nStep 0: Prepare Workspace\n- Import necessary libraries/modules:\n- Functions (e.g., train_test_split, accuracy_score)\n- Classes (e.g., KMeans, KNeighborsClassifier)\nStep 1: Data Preparation\n- Load data (pandas)\n- Clean data (pandas, numpy)\n- Transform/scale features (sklearn.preprocessing)\n- Optionally split data into training and testing sets\nStep 2: Initialize the Model\n- Create an instance of the model class (KMeans, KNeighborsClassifier)\n- Set parameters during instantiation (e.g., n_clusters=3, n_neighbors=5)\n\nStep 3: Fit the Model\n- Use .fit(X) for unsupervised models\n- Use .fit(X_train, y_train) for supervised models\nStep 4: Make Predictions (optional)\n- Use .predict(X_test) to generate predictions\n- Use .predict_proba() to get class probabilities (if available)\nStep 5: Evaluate Model Performance\n- Compare predictions to true values\n- Use visualizations or metrics (e.g., accuracy, ARI, classification report)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-0-import-libraries",
    "href": "session4_newMLDemo/session4v2.html#step-0-import-libraries",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 0: Import Libraries",
    "text": "Step 0: Import Libraries\n\nBefore any analysis, we must import the necessary libraries.\nFor large libraries like scikit-learn, PyTorch, or TensorFlow, we usually do not import the entire package. Instead, we selectively import the classes and functions we need.\n\n\nüî§ Naming Tip:\n- CamelCase = Classes\n- snake_case = Functions"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#import-libraries",
    "href": "session4_newMLDemo/session4v2.html#import-libraries",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Import Libraries",
    "text": "Import Libraries\n\n## imports\nimport pandas as pd\nimport numpy as np\n\nfrom plotnine import *\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom great_tables import GT\n\n## sklearn imports\n\n## import classes\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cluster import KMeans\n\n## import functions\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, adjusted_rand_score"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-1-data-preparation",
    "href": "session4_newMLDemo/session4v2.html#step-1-data-preparation",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 1: Data Preparation",
    "text": "Step 1: Data Preparation\n\n# Load the Penguins dataset\npenguins = sns.load_dataset(\"penguins\").dropna()\n\n# Make a summary table for the penguins dataset, grouping by species. \nsummary_table = penguins.groupby(\"species\").agg({\n    \"bill_length_mm\": [\"mean\", \"std\", \"min\", \"max\"],\n    \"bill_depth_mm\": [\"mean\", \"std\", \"min\", \"max\"],\n    \"flipper_length_mm\": [\"mean\", \"std\", \"min\", \"max\"],\n    \"body_mass_g\": [\"mean\", \"std\", \"min\", \"max\"],\n    \"sex\": lambda x: x.value_counts().to_dict()  # Count of males and females\n})\n\n# Round numeric values to 1 decimal place (excluding the 'sex' column)\nfor col in summary_table.columns:\n    if summary_table[col].dtype in [float, int]:\n        summary_table[col] = summary_table[col].round(1)\n\n# Display the result\ndisplay(summary_table)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-1-data-preparation-output",
    "href": "session4_newMLDemo/session4v2.html#step-1-data-preparation-output",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 1: Data Preparation",
    "text": "Step 1: Data Preparation\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\nmean\nstd\nmin\nmax\nmean\nstd\nmin\nmax\nmean\nstd\nmin\nmax\nmean\nstd\nmin\nmax\n&lt;lambda&gt;\n\n\nspecies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie\n38.8\n2.7\n32.1\n46.0\n18.3\n1.2\n15.5\n21.5\n190.1\n6.5\n172.0\n210.0\n3706.2\n458.6\n2850.0\n4775.0\n{'Male': 73, 'Female': 73}\n\n\nChinstrap\n48.8\n3.3\n40.9\n58.0\n18.4\n1.1\n16.4\n20.8\n195.8\n7.1\n178.0\n212.0\n3733.1\n384.3\n2700.0\n4800.0\n{'Female': 34, 'Male': 34}\n\n\nGentoo\n47.6\n3.1\n40.9\n59.6\n15.0\n1.0\n13.1\n17.3\n217.2\n6.6\n203.0\n231.0\n5092.4\n501.5\n3950.0\n6300.0\n{'Male': 61, 'Female': 58}"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#scaling-the-data---understanding-the-standard-scaler-class",
    "href": "session4_newMLDemo/session4v2.html#scaling-the-data---understanding-the-standard-scaler-class",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Scaling the data - Understanding the Standard Scaler class",
    "text": "Scaling the data - Understanding the Standard Scaler class\nFor our clustering to work well, the predictors should be on the same scale. \nTo achieve this, we use an instance of the StandardScaler class."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#standard-scaler",
    "href": "session4_newMLDemo/session4v2.html#standard-scaler",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Standard Scaler",
    "text": "Standard Scaler\nclass sklearn.preprocessing.StandardScaler(*, copy=True, with_mean=True, with_std=True)\n\n\nParameters are supplied by user\n- copy, with_mean, with_std \nAttributes contain the data of the object\n- scale_: scaling factor\n- mean_: mean value for each feature\n- var_: variance for each feature\n- n_features_in_: number of features seen during fit\n- n_samples_seen: number of samples processed for each feature \nMethods describe the behaviors of the object and/or modify its attributes\n- fit(X) -&gt; compute mean and std used for scaling -&gt; fit scaler to data X\n* updates the attributes of the scaler object\n- transform(X) -&gt; perform standardization by centering and scaling with fitted scaler"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#data-preparation",
    "href": "session4_newMLDemo/session4v2.html#data-preparation",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Data Preparation",
    "text": "Data Preparation\n\n# Selecting features for clustering -&gt; let's just use bill length and bill depth.\nX = penguins[[\"bill_length_mm\", \"bill_depth_mm\"]]\ny = penguins[\"species\"]\n\n# Standardizing the features for better clustering performance\nscaler = StandardScaler() ## create instance of StandardScaler\nX_scaled = scaler.fit_transform(X) ## same as calling scaler.fit(X) then X_scaled = scaler.transform(X)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#understanding-the-kmeans-model-class",
    "href": "session4_newMLDemo/session4v2.html#understanding-the-kmeans-model-class",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Understanding the KMeans model class",
    "text": "Understanding the KMeans model class\nclass sklearn.cluster.KMeans(n_clusters=8, *, init='k-means++', n_init='auto', max_iter=300, \ntol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n\nParameters: Set by user at time of instantiation\n- n_clusters, max_iter, algorithm \nAttributes: Store object data\n- cluster_centers_: stores coordinates of cluster centers\n- labels_: stores labels of each point - n_iter_: number of iterations run (will be changed during method run)\n- n_features_in and feature_names_in_: store info about features seen during fit \nMethods: Define object behaviors\n- fit(X) -&gt; same as usage as train() -&gt; fit model to data X\n- predict(X) -&gt; predict closest cluster each sample in X belongs to\n- transform(X) -&gt; transform X to cluster-distance space"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-2-create-model",
    "href": "session4_newMLDemo/session4v2.html#step-2-create-model",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 2: Create model",
    "text": "Step 2: Create model\n\n## Choosing 3 clusters b/c we have 3 species\nkmeans = KMeans(n_clusters=3, random_state=42) ## make an instance of the K means class"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-3-fit-model-to-data",
    "href": "session4_newMLDemo/session4v2.html#step-3-fit-model-to-data",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 3: Fit model to data",
    "text": "Step 3: Fit model to data\n\n## the fit\npenguins[\"kmeans_cluster\"] = kmeans.fit_predict(X_scaled)\n\n## now that we fit the model, we should have cluster centers\nprint(\"Coordinates of cluster centers:\", kmeans.cluster_centers_)\n\n\n\nCoordinates of cluster centers: [[-0.95023997  0.55393493]\n [ 0.58644397 -1.09805504]\n [ 1.0886843   0.79503579]]"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-5-visualize-and-evaluate",
    "href": "session4_newMLDemo/session4v2.html#step-5-visualize-and-evaluate",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 5: Visualize and Evaluate",
    "text": "Step 5: Visualize and Evaluate\nTo do visualization, we can use either seaborn or plotnine. plotnine mirrors ggplot2 syntax from R and is great for layered grammar-of-graphics plots, while seaborn works directly with numpy arrays and pandas DataFrames. It builds on top of matplotlib objects‚Äîwhich are themselves instances of classes. Most built-in plotting methods in Python packages use matplotlib.\nseaborn is often used for quick statistical visualizations in python and is more convienient if you want to put multiple plots on the same figure."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#use-function-to-calculate-ari",
    "href": "session4_newMLDemo/session4v2.html#use-function-to-calculate-ari",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Use function to calculate ARI",
    "text": "Use function to calculate ARI\nTo check how good our model is, we can use one of the functions included in the sklearn library\nThe adjusted_rand_score() function evaluates how well the cluster groupings agree with the species groupings while adjusting for chance.\n\n# Calculate clustering performance using Adjusted Rand Index (ARI)\nkmeans_ari = adjusted_rand_score(penguins['species'], penguins[\"kmeans_cluster\"])\nprint(f\"k-Means Adjusted Rand Index: {kmeans_ari:.2f}\")\n\n\n\nk-Means Adjusted Rand Index: 0.82"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#we-can-also-use-methods-on-our-data-structure-to-create-new-data",
    "href": "session4_newMLDemo/session4v2.html#we-can-also-use-methods-on-our-data-structure-to-create-new-data",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "We can also use methods on our data structure to create new data",
    "text": "We can also use methods on our data structure to create new data\n\nWe can use the .groupby() method to help us plot cluster agreement with species label\n\n\n# Count occurrences of each species-cluster-sex combination\n# ( .size gives the count as index, use reset_index to get count column. )\nscatter_data = penguins.groupby([\"species\", \"kmeans_cluster\", \"sex\"]).size().reset_index(name=\"count\")\n\n# Create a heatmap of the cluster assignments by species\nheatmap_plot = (\n    ggplot(scatter_data, aes(x=\"species\", y=\"kmeans_cluster\", fill=\"count\"))\n    + geom_tile(color=\"white\")  # Add white grid lines for separation\n    + scale_fill_gradient(low=\"lightblue\", high=\"darkblue\")  # Heatmap colors\n    + labs(\n        title=\"Heatmap of KMeans Clustering by Species\",\n        x=\"Species\",\n        y=\"KMeans Cluster\",\n        fill=\"Count\"\n    )\n    + theme_bw()\n)\n\n# Display the plot\ndisplay(heatmap_plot)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#we-can-also-use-methods-on-our-data-structure-to-create-new-data-output",
    "href": "session4_newMLDemo/session4v2.html#we-can-also-use-methods-on-our-data-structure-to-create-new-data-output",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "We can also use methods on our data structure to create new data",
    "text": "We can also use methods on our data structure to create new data"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#project-2---knn-classification",
    "href": "session4_newMLDemo/session4v2.html#project-2---knn-classification",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Project 2 -> KNN classification",
    "text": "Project 2 -&gt; KNN classification\nFor our KNN classification, the model is supervised (meaning it is dependent on the outcome ‚Äòy‚Äô data) and therefore we need to split our data into a training and test set. \n\nThe function train_test_split() from scikit-learn is helpful here! Our classifier object has built in methods for fitting models and predicting.\n\n# Splitting dataset into training and testing sets (still using scaled X!)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n\n\n\n\nUnlike R functions, which return a single object (often a list when multiple outputs are needed), Python functions can return multiple values as a tuple‚Äîletting you unpack them directly into separate variables."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#understanding-kneighborsclassifier-class",
    "href": "session4_newMLDemo/session4v2.html#understanding-kneighborsclassifier-class",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Understanding KNeighborsClassifier class",
    "text": "Understanding KNeighborsClassifier class\nclass sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', \nalgorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n\nParameters: Set by user at time of instantiation\n- n_neigbors, weights, algorithm, etc. \nAttributes: Store object data\n- classes_: class labels known to the classifier\n- effective_metric_: distance metric used\n- effective_metric_params_: parameters for the metric function\n- n_features_in and feature_names_in_: store info about features seen during fit\n- n_samples_fit_: number of samples in fitted data \nMethods: Define object behaviors\n- .fit(X, y) -&gt; fit knn classifier from training dataset (X and y)\n- .predict(X) -&gt; predict class labels for provided data X\n- .predict_proba(X) -&gt; return probability estimates for test data X\n- .score(X, y) -&gt; return mean accuracy on given test data X and labels y"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#making-an-instance-of-kneighborsclassifier-and-fitting-to-training-data",
    "href": "session4_newMLDemo/session4v2.html#making-an-instance-of-kneighborsclassifier-and-fitting-to-training-data",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Making an instance of KNeighborsClassifier and fitting to training data",
    "text": "Making an instance of KNeighborsClassifier and fitting to training data\n\nFor a supervised model, y_train is included in .fit()!\n\n\n## perform knn classification\n# Applying k-NN classification with 5 neighbors\nknn = KNeighborsClassifier(n_neighbors=5) ## make an instance of the KNeighborsClassifier class\n# and set the n_neighbors parameter to be 5. \n\n# Use the fit method to fit the model to the training data\nknn.fit(X_train, y_train)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#once-the-model-is-fit",
    "href": "session4_newMLDemo/session4v2.html#once-the-model-is-fit",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Once the model is fit‚Ä¶",
    "text": "Once the model is fit‚Ä¶\n\nOnce the model is fit, we can look at its attributes (ex: .classes_) which gives the class labels as known to the classifier\n\n\nprint(knn.classes_)\n\n\n\n['Adelie' 'Chinstrap' 'Gentoo']"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#plotnine-scatterplot-for-k-nn-classification-of-test-data",
    "href": "session4_newMLDemo/session4v2.html#plotnine-scatterplot-for-k-nn-classification-of-test-data",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Plotnine scatterplot for k-NN classification of test data",
    "text": "Plotnine scatterplot for k-NN classification of test data\n\n## Build the plot\nplot3 = (ggplot(penguins_test, aes(x=\"bill_length_mm\", y=\"bill_depth_mm\", \ncolor=\"y_actual\", fill = 'y_pred', size = 'correct'))\n + geom_point()\n + scale_size_manual(values={True: 2, False: 5})\n + ggtitle(\"k-NN Classification Results\")\n + theme_bw())\n\ndisplay(plot3)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#plotnine-scatterplot-for-k-nn-classification-of-test-data-1",
    "href": "session4_newMLDemo/session4v2.html#plotnine-scatterplot-for-k-nn-classification-of-test-data-1",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Plotnine scatterplot for k-NN classification of test data",
    "text": "Plotnine scatterplot for k-NN classification of test data\n\n## Build the plot\nplot3 = (ggplot(penguins_test, aes(x=\"bill_length_mm\", y=\"bill_depth_mm\", \ncolor=\"y_actual\", fill = 'y_pred', size = 'correct'))\n + geom_point()\n + scale_size_manual(values={True: 2, False: 5})\n + ggtitle(\"k-NN Classification Results\")\n + theme_bw())\n\ndisplay(plot3)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#evaluate-knn-performance",
    "href": "session4_newMLDemo/session4v2.html#evaluate-knn-performance",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Evaluate KNN performance",
    "text": "Evaluate KNN performance\n\n## eval knn performance\n# Calculate accuracy and print classification report -&gt; \n# accuracy_score and classification_report are functions! \nknn_accuracy = accuracy_score(y_test, y_pred)\nprint(f\"k-NN Accuracy: {knn_accuracy:.2f}\")\nprint(classification_report(y_test, y_pred))\n\n\n\nk-NN Accuracy: 0.94\n              precision    recall  f1-score   support\n\n      Adelie       0.98      0.98      0.98        48\n   Chinstrap       0.80      0.89      0.84        18\n      Gentoo       0.97      0.91      0.94        34\n\n    accuracy                           0.94       100\n   macro avg       0.92      0.93      0.92       100\nweighted avg       0.94      0.94      0.94       100"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#make-a-summary-table-of-metrics-for-both-models",
    "href": "session4_newMLDemo/session4v2.html#make-a-summary-table-of-metrics-for-both-models",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Make a Summary Table of Metrics for Both Models",
    "text": "Make a Summary Table of Metrics for Both Models\n\n##  making a summary table\n# Creating a summary table\nsummary_table = pd.DataFrame({\n    \"Metric\": [\"k-Means Adjusted Rand Index\", \"k-NN Accuracy\"],\n    \"Value\": [kmeans_ari, knn_accuracy]\n})\nGT(summary_table).show() ## round the values!!!!!\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\nk-Means Adjusted Rand Index\n0.8203520973164866\n\n\nk-NN Accuracy\n0.94"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#key-takeaways-from-this-session",
    "href": "session4_newMLDemo/session4v2.html#key-takeaways-from-this-session",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Key Takeaways from This Session",
    "text": "Key Takeaways from This Session\n\n\n\n\nPython workflows rely on object-oriented structures in addition to functions: Understanding the OOP paradigm makes Python a lot easier!\n\n\nEverything is an object!\n\n\nDuck Typing: If an object has a method, that method can be called regardless of the object type. Caveat being, make sure the arguments (if any) in the method are specified correctly for all objects!\n\n\nPython packages use common methods that make it easy to change between model types without changing a lot of code."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#pre-reading-for-this-session",
    "href": "session4_newMLDemo/session4v2.html#pre-reading-for-this-session",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Pre-Reading for This Session",
    "text": "Pre-Reading for This Session\n\nScikit-learn Documentation\n\nIntroduction to OOP in Python (Real Python)\n\nPlotnine Reference"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#key-principles-of-oop",
    "href": "session4_newMLDemo/session4v2.html#key-principles-of-oop",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Key Principles of OOP",
    "text": "Key Principles of OOP\n\nEncapsulation: Bundling data and methods together in a single unit.\n\nA StandardScaler object stores mean and variance data and has .fit() and .transform() methods\n\nInheritance: Creating new classes based on existing ones.\n\nsklearn.LinearRegression inherits from a general regression model class.\n\nAbstraction: Hiding implementation details and exposing only essential functionality.\n\ne.g., .fit() works the same way from the outside, regardless of model complexity\n\nPolymorphism: Objects of different types can be treated the same way if they implement the same methods.\n\ne.g., any object with .fit() and .predict() can be passed into a pipeline\nPython‚Äôs duck typing:\n\n‚ÄúIf it walks like a duck and quacks like a duck, then it must be a duck.‚Äù\n\nIf an object has the right attributes and methods, it can be used in the same way as another object of a different class."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#duck-typing",
    "href": "session4_newMLDemo/session4v2.html#duck-typing",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Duck Typing",
    "text": "Duck Typing\n\n‚ÄúIf it quacks like a duck and walks like a duck, it‚Äôs a duck.‚Äù\n\nPython doesn‚Äôt require explicit interfaces. If an object implements the expected methods, it can be used interchangeably with other objects. This is called duck typing.\n\nWe can demonstrate this by defining two new base classes that are different than Dog but also have a speak() method.\n\n\n\nclass Human:\n    def __init__(self, name):\n        self.name = name\n\n    def speak(self):\n        return f\"{self.name} says hello!\"\n\nclass Parrot:\n    def __init__(self, name):\n        self.name = name\n\n    def speak(self):\n        return f\"{self.name} says squawk!\""
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#duck-typing-in-action",
    "href": "session4_newMLDemo/session4v2.html#duck-typing-in-action",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Duck Typing in Action",
    "text": "Duck Typing in Action\nEven though Dog, Human and Parrot are entirely different classes‚Ä¶\n\ndef call_speaker(obj):\n    print(obj.speak())\n\ncall_speaker(Dog(\"Fido\", \"Labrador\"))\ncall_speaker(Human(\"Alice\"))\ncall_speaker(Parrot(\"Polly\"))\n\n\n\nFido says woof!\nAlice says hello!\nPolly says squawk!\n\n\n\nThey all implement .speak(), so Python treats them the same!\nIn the context of our work, this would allow us to make a pipeline using models from different libraries that do not share a base class/mixin but have the same methods."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#additional-insights",
    "href": "session4_newMLDemo/session4v2.html#additional-insights",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Additional Insights",
    "text": "Additional Insights\n\n\n\nPredictable APIs enable seamless model switching: Swapping models like LogisticRegression ‚Üí RandomForestClassifier usually requires minimal code changes.\n\n\nscikit-learn prioritizes interoperability: Its consistent class design integrates with tools like Pipeline, GridSearchCV, and cross_val_score.\n\n\nClass attributes improve model transparency: Access attributes like .coef_, .classes_, and .feature_importances_ for model interpretation and debugging.\n\n\nCustom classes are central to deep learning: Frameworks like PyTorch and TensorFlow require you to define your own model classes by subclassing base models.\n\n\nMixins support modular design: Mixins (e.g., ClassifierMixin) let you add specific functionality without duplicating code."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#plotting-with-plotnine-vs-seaborn",
    "href": "session4_newMLDemo/session4v2.html#plotting-with-plotnine-vs-seaborn",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Plotting with plotnine vs seaborn",
    "text": "Plotting with plotnine vs seaborn\n\n\nplotnine (like ggplot2 in R)\nThe biggest differences between plotnine and ggplot2 syntax are: - With plotnine the whole call is wrapped in () parentheses - Variables are called with strings (\"\" are needed!) - If you don‚Äôt use from plotnine import *, you will need to import each individual function you plan to use!\n\nseaborn (base matplotlib + enhancements)\n\nDesigned for quick, polished plots\nWorks well with pandas DataFrames or NumPy arrays\nIntegrates with matplotlib for customization\nOften used in ML for things like decision boundaries or heatmaps"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#scatterplot-with-plotnine",
    "href": "session4_newMLDemo/session4v2.html#scatterplot-with-plotnine",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Scatterplot with plotnine",
    "text": "Scatterplot with plotnine\nTo take at the distribution of our species by bill length and bill depth‚Ä¶\n\n# Plotnine scatterplot of species by bill length/depth\nplot1 = (ggplot(penguins, aes(x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\"))\n + geom_point()\n + ggtitle(\"Penguin Species\")\n + theme_bw())\n\ndisplay(plot1)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#scatterplot-with-plotnine-output",
    "href": "session4_newMLDemo/session4v2.html#scatterplot-with-plotnine-output",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Scatterplot with plotnine",
    "text": "Scatterplot with plotnine"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#scatterplot-with-seaborn",
    "href": "session4_newMLDemo/session4v2.html#scatterplot-with-seaborn",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Scatterplot with seaborn",
    "text": "Scatterplot with seaborn\nWe can also create a plot for the K-means clustering results. This time, we‚Äôll use seaborn.\n\n# Create the figure and axes\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Save seaborn scatterplot to variable plot1 by drawing it on ax\nplot1 = sns.scatterplot(\n    data=penguins,\n    x=\"bill_length_mm\",\n    y=\"bill_depth_mm\",\n    hue=\"species\",\n    style=\"sex\",             # optional\n    palette=\"Set2\",\n    edgecolor=\"black\",\n    s=100,\n    ax=ax                    # draw on the axes object\n)\n\n# Add decorations to the same Axes\nax.set_title(\"Penguin Bill Length vs Depth by Species\")\nax.set_xlabel(\"Bill Length (mm)\")\nax.set_ylabel(\"Bill Depth (mm)\")\nax.legend(title=\"Species\")\n\n# Plot the figure\nfig.tight_layout()"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#scatterplot-with-seaborn-output",
    "href": "session4_newMLDemo/session4v2.html#scatterplot-with-seaborn-output",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Scatterplot with seaborn",
    "text": "Scatterplot with seaborn"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#next-step-use-fitted-model-to-predict-species-for-test-data",
    "href": "session4_newMLDemo/session4v2.html#next-step-use-fitted-model-to-predict-species-for-test-data",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Next Step: Use fitted model to predict species for test data",
    "text": "Next Step: Use fitted model to predict species for test data\n\n# Use the predict method on the test data to get the predictions for the test data\ny_pred = knn.predict(X_test)\n\n# Also can take a look at the prediction probabilities, \n# and use the .classes_ attribute to put the column labels in the right order\nprobs = pd.DataFrame(\n    knn.predict_proba(X_test),\n    columns = knn.classes_)\nprobs['y_pred'] = y_pred\n\nprint(\"Predicted probabilities: \\n\", probs.head())\n\n\n\nPredicted probabilities: \n    Adelie  Chinstrap  Gentoo     y_pred\n0     1.0        0.0     0.0     Adelie\n1     0.0        0.0     1.0     Gentoo\n2     1.0        0.0     0.0     Adelie\n3     0.0        0.6     0.4  Chinstrap\n4     1.0        0.0     0.0     Adelie"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#scatterplot-for-k-nn-classification-of-test-data",
    "href": "session4_newMLDemo/session4v2.html#scatterplot-for-k-nn-classification-of-test-data",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Scatterplot for k-NN classification of test data",
    "text": "Scatterplot for k-NN classification of test data\n\nCreate dataframe of unscaled X_test, bill_length_mm, and bill_depth_mm.\nAdd to it the actual and predicted species labels\n\n\n## First unscale the test data\nX_test_unscaled = scaler.inverse_transform(X_test)\n\n## create dataframe \npenguins_test = pd.DataFrame(\n    X_test_unscaled,\n    columns=['bill_length_mm', 'bill_depth_mm']\n)\n\n## add actual and predicted species \npenguins_test['y_actual'] = y_test.values\npenguins_test['y_pred'] = y_pred\npenguins_test['correct'] = penguins_test['y_actual'] == penguins_test['y_pred']"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#plotnine-scatterplot-for-k-nn-classification-of-test-data-output",
    "href": "session4_newMLDemo/session4v2.html#plotnine-scatterplot-for-k-nn-classification-of-test-data-output",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Plotnine scatterplot for k-NN classification of test data",
    "text": "Plotnine scatterplot for k-NN classification of test data"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#visualizing-decision-boundary-with-seaborn-and-matplotlib",
    "href": "session4_newMLDemo/session4v2.html#visualizing-decision-boundary-with-seaborn-and-matplotlib",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Visualizing Decision Boundary with seaborn and matplotlib",
    "text": "Visualizing Decision Boundary with seaborn and matplotlib\n\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.preprocessing import LabelEncoder\n\n# Create and fit label encoder for y (just makes y numeric because it makes the scatter plot happy)\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Create the plot objects\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Create display object\ndisp = DecisionBoundaryDisplay.from_estimator(\n    knn,\n    X_test,\n    response_method = 'predict',\n    plot_method = 'pcolormesh',\n    xlabel = \"bill_length_scaled\",\n    ylabel = \"bill_depth_scaled\",\n    shading = 'auto',\n    alpha = 0.5,\n    ax = ax\n)\n\n# Use method from display object to create scatter plot\nscatter = disp.ax_.scatter(X_scaled[:,0], X_scaled[:,1], c=y_encoded, edgecolors = 'k')\ndisp.ax_.legend(\n    scatter.legend_elements()[0],\n    knn.classes_,\n    loc = 'lower left',\n    title = 'Species'\n    \n)\n_ = disp.ax_.set_title(\"Penguin Classification\")\n\nplt.show()"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#visualizing-decision-boundary-with-seaborn-and-matplotlib-output",
    "href": "session4_newMLDemo/session4v2.html#visualizing-decision-boundary-with-seaborn-and-matplotlib-output",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Visualizing Decision Boundary with seaborn and matplotlib",
    "text": "Visualizing Decision Boundary with seaborn and matplotlib"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#quick-recap-programming-styles-r-vs-python",
    "href": "session4_newMLDemo/session4v2.html#quick-recap-programming-styles-r-vs-python",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Quick Recap: Programming Styles: R vs Python",
    "text": "Quick Recap: Programming Styles: R vs Python\n In the first session, we talked briefly about functional vs object-oriented programming:\n Functional programming: focuses on functions as the primary unit of code  Object-oriented programming: uses objects with attached attributes(data) and methods(behaviors) \n\nR leans heavily on the functional paradigm ‚Äî you pass data into functions and get back results. Functions and pipes (%&gt;%) dominate most workflows.\nIn Python, everything is an object, even basic things like lists, strings, and dataframes. Understanding how this works is key to using Python effectively.\n\n\nYou‚Äôve already seen this object-oriented style in Sessions 2 and 3 ‚Äî you create objects like lists or dataframes, then call methods on them like .append() or .sort_values()."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#why-oop-matters-in-python-modeling",
    "href": "session4_newMLDemo/session4v2.html#why-oop-matters-in-python-modeling",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Why OOP Matters in Python Modeling",
    "text": "Why OOP Matters in Python Modeling\nThis approach makes model behavior consistent and helps manage complexity in larger projects.\nIn Python modeling frameworks:\n\nModels are instances of classes\n\nYou call methods like .fit(), .predict(), .score()\n\nInternal model details like coefficients or layers are stored as attributes\n\n\nInstead of calling functions and passing in data, we create a model object and then call methods on that object:\nmodel = LogisticRegression()  # create object\nmodel.fit(X, y)               # call a method on the object\n\n\nüß™ If you‚Äôre used to lm() or glm() in R returning a list of values, think of the Python approach as a self-contained object with named methods and stored results. We‚Äôll focus on scikit-learn here for the sake of simplicity, but feel free to explore the others!"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#common-modeling-libraries-in-python",
    "href": "session4_newMLDemo/session4v2.html#common-modeling-libraries-in-python",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Common Modeling Libraries in Python",
    "text": "Common Modeling Libraries in Python\nHere‚Äôs how Python‚Äôs most common modeling libraries apply OOP in practice:\n\n\n\n\n\n\n\n\nLibrary\nDomain\nOOP Style\n\n\n\n\nscikit-learn\nGeneral machine learning\nPrebuilt classes like LogisticRegression, KMeans\n\n\nstatsmodels\nStatistical modeling\nR-like syntax and outputs\n\n\nPyTorch\nDeep learning\nDefine custom model classes using inheritance\n\n\nTensorFlow\nDeep learning / ML ops\nLayered, object-oriented model building\n\n\n\n\nscikit-learn is great for getting started‚Äîeverything from regression to clustering follows a simple, consistent OOP interface.\nPyTorch and TensorFlow are essential if you go deeper into neural networks or custom models‚Äîyou‚Äôll define your own model classes using inheritance.\nstatsmodels provides a nice bridge if you‚Äôre coming from R: you still create model objects with .fit() methods, but use formula-style syntax like in lm().\n\n\nWe‚Äôll focus on scikit-learn here for the sake of simplicity, but feel free to explore the others!"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#programming-styles-r-vs-python",
    "href": "session4_newMLDemo/session4v2.html#programming-styles-r-vs-python",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Programming Styles: R vs Python",
    "text": "Programming Styles: R vs Python\n In the first session, we talked briefly about functional vs object-oriented programming:\n\n\nFunctional programming: focuses on functions as the primary unit of code  Object-oriented programming: uses objects with attached attributes(data) and methods(behaviors) \n\n\nR leans heavily on the functional paradigm ‚Äî you pass data into functions and get back results, in most cases without altering the original data. Functions and pipes (%&gt;%) dominate most workflows.\nIn Python, everything is an object, even basic things like lists, strings, and dataframes, and a lot of ‚Äòfunctions‚Äô are written as object-associated methods. Some of these methods modify the objects in-place by altering the attached data (attributes). Understanding how this works is key to using Python effectively!\n\n\nYou‚Äôve already seen this object-oriented style in Sessions 2 and 3 ‚Äî you create objects like lists or dataframes, then call methods on them like .append() or .sort_values(). In python, instead of piping, we sometimes chain methods together."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#why-does-oop-matter-in-python-modeling",
    "href": "session4_newMLDemo/session4v2.html#why-does-oop-matter-in-python-modeling",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Why Does OOP Matter in Python Modeling?",
    "text": "Why Does OOP Matter in Python Modeling?\n\nIn Python modeling frameworks:\n\n\n\nModels are instances of classes\n\n\nYou call methods like .fit(), .predict(), .score()\n\n\nInternal model details like coefficients or layers are stored as attributes\n\n\n\nThis makes model behavior consistent and helps manage complexity of things like pipelines that are designed to work for multiple model classes. It also simplifies creating/using pre-trained models: both the architecture and learned weights are bundled into a single object with built-in methods like .predict() or .fine_tune().\n\n\nIf you‚Äôre used to lm() or glm() in R returning a list of values, think of the Python approach as a self-contained object with named methods and stored results. Instead of having a separate results object, like in R, you would retrieve your results by accessing an attribute that is stored in the model object itself.\n\n\nWe‚Äôll focus on scikit-learn here for the sake of simplicity, but feel free to explore other libraries! \nhttps://wesmckinney.com/book/modeling is a good tutorial for statsmodels."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#classes-and-objects",
    "href": "session4_newMLDemo/session4v2.html#classes-and-objects",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Classes and Objects",
    "text": "Classes and Objects\n\nClasses are blueprints for creating objects. Each object contains:\n\n\n\nAttributes (data): model coefficients, class labels\n\n\nMethods (behaviors): .fit(), .predict()\n\n\n\nüëâ To check if an object is an instance of a particular class, use:\n\nisinstance(object, class)  # Returns True if `object` is an instance of `class`.\n\n\n\nKnowing what class an object belongs to helps us understand what methods and attributes it provides."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#creating-a-class",
    "href": "session4_newMLDemo/session4v2.html#creating-a-class",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Creating a Class",
    "text": "Creating a Class\nClasses are defined using the class keyword, and their structure is specified using an __init__() method for initialization.\n\nFor example, we can define a class called Dog and give it attributes that store data about a given dog.\nWe can also add methods that represent behaviors an object of the Dog class can perform:\n\n\n\nclass Dog: ## begin class definition\n    def __init__(self, name, breed): ## define init method\n        self.name = name ## add attributes\n        self.breed = breed\n\n    def speak(self): ## add methods\n        return f\"{self.name} says woof!\""
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#oop-in-machine-learning-and-modeling",
    "href": "session4_newMLDemo/session4v2.html#oop-in-machine-learning-and-modeling",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "OOP in Machine Learning and Modeling?",
    "text": "OOP in Machine Learning and Modeling?\nMachine learning models in Python are implemented as classes.\n- When you create a model, you‚Äôre instantiating an object of a predefined class (e.g., LogisticRegression()).\n- That model inherits attributes (parameters, coefficients) and methods (like .fit() and .predict())."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#key-oop-principles-recap",
    "href": "session4_newMLDemo/session4v2.html#key-oop-principles-recap",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Key OOP Principles (Recap)",
    "text": "Key OOP Principles (Recap)\nIn OOP, code is structured around objects (as opposed to functions). This paradigm builds off the following principles:\n\n\nEncapsulation: Bundling data and methods together in a single unit.\n\nA StandardScaler object stores mean and variance data and has .fit() and .transform() methods\n\n\n\n\n\nInheritance: Creating new classes based on existing ones.\n\nsklearn.LinearRegression inherits attributes and methods from a general regression model class.\n\n\n\n\n\nAbstraction: Hiding implementation details and exposing only essential functionality.\n\ne.g., .fit() works the same way from the outside, regardless of model complexity\n\n\n\n\n\nPolymorphism: Objects of different types can be treated the same way if they implement the same methods.\n\nPython‚Äôs duck typing:\n\n‚ÄúIf it walks like a duck and quacks like a duck, then it must be a duck.‚Äù\n\nex: If different objects all have a .summarize() method, we can loop over them and call .summarize() without needing to check their class. As long as the method exists, Python will know what to do.\nThis lets us easily create pipelines that can work for many types of models.\n\n\n\n\nWe won‚Äôt cover pipelines here, but they are worth looking into!"
  }
]