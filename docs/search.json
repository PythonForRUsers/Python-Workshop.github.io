[
  {
    "objectID": "session4_newMLDemo/session4v2.html#session-overview",
    "href": "session4_newMLDemo/session4v2.html#session-overview",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Session Overview",
    "text": "Session Overview\nThis session is divided into two parts:\n1. A quick recap of Object-Oriented Programming (OOP) and why it‚Äôs useful.\n2. Applying OOP concepts to machine learning by building models in scikit-learn."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#introduction",
    "href": "session4_newMLDemo/session4v2.html#introduction",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Introduction",
    "text": "Introduction\nBoth R and python use objects, but not everything in R is object-oriented‚Ä¶ If that sounds confusing that‚Äôs because it is! \nFunctional programming: focuses on functions as the primary unit of code \nObject-oriented programming: uses objects with attached attributes(data) and methods(behaviors) \nFunctional and object-oriented programming are paradigms (styles) and these styles can be applied in both R and Python. However, Python libraries and workflows tend to rely more on object-oriented programming than those designed for R.\n\nR originated from another statistical programming language called S, which is not object-oriented, and R tends to lend itself better to functional programming than object-oriented programming in many cases."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#why-python",
    "href": "session4_newMLDemo/session4v2.html#why-python",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Why Python? üêç",
    "text": "Why Python? üêç\n\nR built by statisticians for statisticians:\n\nExcels at statistical analysis and modeling\nBeautiful data visualizations with fairly simple code\n\nPython is a general purpose language (like C++, Java):\n\nExcels at deep learning, image analysis, text analysis\nBut also:\n\nAutomation\nSoftware/Application development (including CLI [command line interface])\nWeb development \n\n\n\nPython is a good go-to for many things that R isn‚Äôt quite suited for and is very flexible. There are also packages like rpy2 and reticulate that make it easy to use both R and Python in the same project, but those are beyond the scope of this course. A primer on reticulate https://www.r-bloggers.com/2022/04/getting-started-with-python-using-r-and-reticulate/"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#functions-vs-objects-in-python",
    "href": "session4_newMLDemo/session4v2.html#functions-vs-objects-in-python",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Functions vs Objects in Python",
    "text": "Functions vs Objects in Python\nPython absolutely still uses functions (just like R), and they‚Äôre incredibly useful‚Äîparticularly for data transformations, wrangling, or tasks like parallel processing.\nBut when it comes to modeling, the dominant paradigm is object-oriented"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#why-oop-matters-in-python",
    "href": "session4_newMLDemo/session4v2.html#why-oop-matters-in-python",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Why OOP Matters in Python",
    "text": "Why OOP Matters in Python\nMany of the most popular Python libraries for modeling‚Äîsuch as scikit-learn, statsmodels, PyTorch, and TensorFlow‚Äîare built around the principles of object-oriented programming (OOP).\nThis means that to work effectively in Python, especially for tasks involving modeling or model training, it helps to think in terms of objects and classes, not just functions.\n\nModels in Python:\n\nTypically instances of classes\nCome with built-in methods (like .fit() or .predict()) and attributes (like .coef_) that define their behavior and internal state"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#why-oop-matters-for-machine-learning-modeling",
    "href": "session4_newMLDemo/session4v2.html#why-oop-matters-for-machine-learning-modeling",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Why OOP Matters for Machine Learning/ Modeling",
    "text": "Why OOP Matters for Machine Learning/ Modeling\nIf you‚Äôre doing machine learning, deep learning, or building custom models in Python, you‚Äôre often working in domains where R doesn‚Äôt offer as much built-in support. That‚Äôs where packages like:\n\nscikit-learn (machine learning)\nPyTorch and TensorFlow (deep learning and neural networks)\n\ncome in.\n\nScikit-learn provides a wide array of ready-to-use model classes, making it a great entry point\nPyTorch and TensorFlow, especially for custom neural network architectures, require you to create your own classes using inheritance from base classes and mixins\n\nI won‚Äôt go deep into PyTorch or TensorFlow here, but feel free to ask me later or explore tutorials online if you‚Äôre curious!"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#statsmodels",
    "href": "session4_newMLDemo/session4v2.html#statsmodels",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Statsmodels",
    "text": "Statsmodels\n\nStatsmodels offers a more R-like interface for regression models but requires some additional setup for design matrices. (You can check out their excellent documentation here.)\n\nI won‚Äôt cover statsmodels here, but it is worth looking up if you are interested."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#what-well-cover",
    "href": "session4_newMLDemo/session4v2.html#what-well-cover",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "What We‚Äôll Cover",
    "text": "What We‚Äôll Cover\nTo get comfortable with this way of thinking, we‚Äôll first do a brief recap of object-oriented programming‚Äîwhat classes are, how inheritance works, and how you can define your own classes in Python.\n\nThen we‚Äôll shift focus to using model classes in Python, particularly with scikit-learn.\n\nWhether you‚Äôre using a prebuilt model class or writing your own from scratch, the workflow is often similar. You‚Äôll still need to define or use common methods like .fit(), .predict(), and .score(), and understand how the model stores internal data like coefficients and hyperparameters."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#recap-what-are-classes-and-objects",
    "href": "session4_newMLDemo/session4v2.html#recap-what-are-classes-and-objects",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Recap: What Are Classes and Objects?",
    "text": "Recap: What Are Classes and Objects?\nA class is a blueprint for creating objects. An object is an instance of a class that contains data (attributes) and behaviors (methods).\n\nFor example, in Python, we can define a class called Dog and give it attributes that store data about a given dog.\nWe can also define methods that represent behaviors an object of the dog class can perform:\n\n\n\nclass Dog:\n    def __init__(self, name, breed):\n        self.name = name\n        self.breed = breed\n\n    def speak(self):\n        return f\"{self.name} says woof!\""
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#creating-a-dog",
    "href": "session4_newMLDemo/session4v2.html#creating-a-dog",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Creating a dog",
    "text": "Creating a dog\nCreating an instance (object) of the Dog class lets us model a particular dog:\n\n\nmy_dog = Dog(\"Buddy\", \"Golden Retriever\")\nprint(my_dog.speak())  \n\n\n\nBuddy says woof!\n\n\n\n\nHere, my_dog is an object of the Dog class.\nIt has attributes (name, breed) and methods (speak()).\n\n\nWhen we make an instance of the Dog class:\n- We set the value of the attributes [name and breed], which are then stored as part of the my_dog object\n- We can use any methods defined in the Dog class on my_dog\n\n\nNote: For python methods, the self argument is assumed to be passed and therefore we do not put anything in the parentheses when calling .speak()."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#how-does-this-relate-to-machine-learning-and-modeling",
    "href": "session4_newMLDemo/session4v2.html#how-does-this-relate-to-machine-learning-and-modeling",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "How Does This Relate to Machine Learning and Modeling?",
    "text": "How Does This Relate to Machine Learning and Modeling?\n\nMachine learning models in Python are implemented as classes.\n- When you create a model, you‚Äôre instantiating an object of a predefined class (e.g., LogisticRegression()).\n- That model inherits attributes (parameters, coefficients) and methods (like .fit() and .predict())."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#key-benefits-of-oop-in-machine-learning",
    "href": "session4_newMLDemo/session4v2.html#key-benefits-of-oop-in-machine-learning",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Key Benefits of OOP in Machine Learning",
    "text": "Key Benefits of OOP in Machine Learning\n\nEncapsulation ‚Äì Models store parameters and methods inside a single object.\n\nInheritance ‚Äì New models can build on base models, reusing existing functionality.\n\nAbstraction ‚Äì .fit() should work as expected, regardless of complexity of underlying implimentation.\nPolymorphism ‚Äì Different models share the same method names (.fit(), .predict()), making them easy to use interchangeably."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#example-understanding-classes---definition-inheritance-mixins",
    "href": "session4_newMLDemo/session4v2.html#example-understanding-classes---definition-inheritance-mixins",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Example: Understanding Classes - Definition, Inheritance, Mixins",
    "text": "Example: Understanding Classes - Definition, Inheritance, Mixins\nBefore we get into the machine learning demo projects, I want to quickly demonstrate how classes work and how we can leverage inheritance when making our own classes.\nEven though this example is very simple, the same method applies to making your own classes for machine learning and neural network models."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#base-classes",
    "href": "session4_newMLDemo/session4v2.html#base-classes",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Base Classes",
    "text": "Base Classes\nA base class (or parent class) serves as a template for creating objects. Other classes can inherit from it to reuse its properties and methods.\nFor example, the class we created earlier, Dog, could be a base class.\n\nclass Dog: ## class definition\n    def __init__(self, name, breed): ## sets up the initialization for an instance of class Dog. \n        ### Allows us to assign name and breed when we instantiate dog. \n        self.name = name ## attributes\n        self.breed = breed\n\n    def speak(self): ## method\n        return f\"{self.name} says Woof!\"\n\n\nAnd we can make an instance of Dog and make it do things.\n\nmy_dog = Dog(\"Fido\", \"Labrador\") ## create a dog of name 'Fido' and breed 'Labrador'\nprint(my_dog.speak())\n\n## if we want to see what kind of dog our dog is\nprint(f\"Our dog {my_dog.name} is a {my_dog.breed}.\")\n\n\n\nFido says Woof!\nOur dog Fido is a Labrador."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#derived-child-classes",
    "href": "session4_newMLDemo/session4v2.html#derived-child-classes",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Derived (Child) Classes",
    "text": "Derived (Child) Classes\nNow that we have a Dog class, let‚Äôs define a new class called GuardDog. This class will inherit all the properties and methods from Dog, while also adding its own unique attributes and behaviors.\nThis is the power of inheritance‚Äîwe don‚Äôt have to rewrite everything from scratch! Instead, we can extend the existing functionality of Dog to create a more specialized class."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#mixins",
    "href": "session4_newMLDemo/session4v2.html#mixins",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Mixins",
    "text": "Mixins\nA mixin is a special kind of class designed to add functionality to another class. Unlike base classes, mixins aren‚Äôt used alone.\nFor example, scikit-learn uses mixins like:\n- sklearn.base.ClassifierMixin (adds classifier-specific methods)\n- sklearn.base.RegressorMixin (adds regression-specific methods)\nwhich it adds to the BaseEstimator class to add functionality.\nTo finish up our dog example, we are going to define a mixin class that adds a functionality to the base Dog() class which allows us to teach a dog tricks."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#oop-in-ml-recap",
    "href": "session4_newMLDemo/session4v2.html#oop-in-ml-recap",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "OOP In ML Recap",
    "text": "OOP In ML Recap\nUnderstanding base classes and mixins is especially important when working with deep learning frameworks like PyTorch and TensorFlow, as they allow for easy customization of models.\nBy using object-oriented programming, Python makes it easy to structure machine learning workflows in a reusable and scalable way. The fact that all ML models in scikit-learn follow the same structure (with .fit(), .predict(), .score(), etc.) makes it easier to switch between models and automate processes. Additionally, the model classes in the statsmodels package have many of the same methods (.fit(), .predict(), .score())."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#mini-project-classifying-penguins-with-scikit-learn",
    "href": "session4_newMLDemo/session4v2.html#mini-project-classifying-penguins-with-scikit-learn",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "üêß Mini Project: Classifying Penguins with scikit-learn",
    "text": "üêß Mini Project: Classifying Penguins with scikit-learn\nNow that you understand classes and data structures in Python, let‚Äôs apply that knowledge!\nIn this project, we‚Äôll try to classify penguin species using two features:\n- bill_length_mm\n- bill_depth_mm\nWe‚Äôll explore: - Unsupervised learning with K-Means clustering (model doesn‚Äôt ‚Äòknow‚Äô y) - Supervised learning with a k-NN classifier (model trained w/ y information)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#modeling-with-scikit-learn-classes",
    "href": "session4_newMLDemo/session4v2.html#modeling-with-scikit-learn-classes",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Modeling with scikit-learn Classes",
    "text": "Modeling with scikit-learn Classes\nWe‚Äôll use models from scikit-learn, which are built using object-oriented design.\nEach model is an instance of a class (inheriting from BaseEstimator) with:\nCommon Methods:\n- .fit() ‚Äî Train the model\n- .predict() ‚Äî Make predictions\nCommon Attributes:\n- .get_params(), .classes_, .n_clusters_, etc.\n\nWe‚Äôre using scikit-learn here for its simplicity, but the concepts apply to more advanced frameworks like PyTorch and TensorFlow too!"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#general-modeling-workflow",
    "href": "session4_newMLDemo/session4v2.html#general-modeling-workflow",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "General Modeling Workflow",
    "text": "General Modeling Workflow\n\n\nStep 0: Prepare Workspace\n- Import necessary libraries/modules:\n- Functions (e.g., train_test_split, accuracy_score)\n- Classes (e.g., KMeans, KNeighborsClassifier)\nStep 1: Data Preparation\n- Load data (pandas)\n- Clean data (pandas, numpy)\n- Transform/scale features (sklearn.preprocessing)\n- Optionally split data into training and testing sets\nStep 2: Initialize the Model\n- Create an instance of the model class (KMeans, KNeighborsClassifier)\n- Set parameters during instantiation (e.g., n_clusters=3, n_neighbors=5)\n\nStep 3: Fit the Model\n- Use .fit(X) for unsupervised models\n- Use .fit(X_train, y_train) for supervised models\nStep 4: Make Predictions (optional)\n- Use .predict(X_test) to generate predictions\n- Use .predict_proba() to get class probabilities (if available)\nStep 5: Evaluate Model Performance\n- Compare predictions to true values\n- Use visualizations or metrics (e.g., accuracy, ARI, classification report)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-0-import-libraries",
    "href": "session4_newMLDemo/session4v2.html#step-0-import-libraries",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 0: Import Libraries",
    "text": "Step 0: Import Libraries\n\nBefore any analysis, we must import the necessary libraries.\nFor large libraries like scikit-learn, PyTorch, or TensorFlow, we usually do not import the entire package. Instead, we selectively import the classes and functions we need.\n\n\nüî§ Naming Tip:\n- CamelCase = Classes\n- snake_case = Functions"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#import-libraries",
    "href": "session4_newMLDemo/session4v2.html#import-libraries",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Import Libraries",
    "text": "Import Libraries\n\n## imports\nimport pandas as pd\nimport numpy as np\n\nfrom plotnine import *\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom great_tables import GT\nfrom tabulate import tabulate\n\n## sklearn imports\n\n## import classes\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cluster import KMeans\n\n## import functions\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, adjusted_rand_score"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-1-data-preparation",
    "href": "session4_newMLDemo/session4v2.html#step-1-data-preparation",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 1: Data Preparation",
    "text": "Step 1: Data Preparation\n\n# Load the Penguins dataset\npenguins = sns.load_dataset(\"penguins\").dropna()\n\n# Make a summary table for the penguins dataset, grouping by species. \nsummary_table = penguins.groupby(\"species\").agg({\n    \"bill_length_mm\": [\"mean\", \"std\", \"min\", \"max\"],\n    \"bill_depth_mm\": [\"mean\", \"std\", \"min\", \"max\"],\n    \"flipper_length_mm\": [\"mean\", \"std\", \"min\", \"max\"],\n    \"body_mass_g\": [\"mean\", \"std\", \"min\", \"max\"],\n    \"sex\": lambda x: x.value_counts().to_dict()  # Count of males and females\n})\n\n# Round numeric values to 1 decimal place (excluding the 'sex' column)\nfor col in summary_table.columns:\n    if summary_table[col].dtype in [float, int]:\n        summary_table[col] = summary_table[col].round(1)\n\n# Display the result\ndisplay(summary_table)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-1-data-preparation-output",
    "href": "session4_newMLDemo/session4v2.html#step-1-data-preparation-output",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 1: Data Preparation",
    "text": "Step 1: Data Preparation\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\nmean\nstd\nmin\nmax\nmean\nstd\nmin\nmax\nmean\nstd\nmin\nmax\nmean\nstd\nmin\nmax\n&lt;lambda&gt;\n\n\nspecies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie\n38.8\n2.7\n32.1\n46.0\n18.3\n1.2\n15.5\n21.5\n190.1\n6.5\n172.0\n210.0\n3706.2\n458.6\n2850.0\n4775.0\n{'Male': 73, 'Female': 73}\n\n\nChinstrap\n48.8\n3.3\n40.9\n58.0\n18.4\n1.1\n16.4\n20.8\n195.8\n7.1\n178.0\n212.0\n3733.1\n384.3\n2700.0\n4800.0\n{'Female': 34, 'Male': 34}\n\n\nGentoo\n47.6\n3.1\n40.9\n59.6\n15.0\n1.0\n13.1\n17.3\n217.2\n6.6\n203.0\n231.0\n5092.4\n501.5\n3950.0\n6300.0\n{'Male': 61, 'Female': 58}"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#scaling-the-data---understanding-the-standard-scaler-class",
    "href": "session4_newMLDemo/session4v2.html#scaling-the-data---understanding-the-standard-scaler-class",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Scaling the data - Understanding the Standard Scaler class",
    "text": "Scaling the data - Understanding the Standard Scaler class\nFor our clustering to work well, the predictors should be on the same scale. \nTo achieve this, we use an instance of the StandardScaler class."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#standard-scaler",
    "href": "session4_newMLDemo/session4v2.html#standard-scaler",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Standard Scaler",
    "text": "Standard Scaler\nclass sklearn.preprocessing.StandardScaler(*, copy=True, with_mean=True, with_std=True)\n . . .\nParameters are supplied by user\n- copy, with_mean, with_std\n\nAttributes contain the data of the object\n- scale_: scaling factor - mean_: mean value for each feature - var_: variance for each feature - n_features_in_: number of features seen nduring fit - n_samples_seen: number of samples processed for each feature \nMethods describe the behaviors of the object and/or modify its attributes\n- fit(X) -&gt; compute mean and std used for scaling -&gt; fit scaler to data X * updates the attributes of the scaler object - transform(X) -&gt; perform standardization by centering and scaling with fitted scaler"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#data-preparation",
    "href": "session4_newMLDemo/session4v2.html#data-preparation",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Data Preparation",
    "text": "Data Preparation\n\n# Selecting features for clustering -&gt; let's just use bill length and bill depth.\nX = penguins[[\"bill_length_mm\", \"bill_depth_mm\"]]\ny = penguins[\"species\"]\n\n# Standardizing the features for better clustering performance\nscaler = StandardScaler() ## create instance of StandardScaler\nX_scaled = scaler.fit_transform(X) ## same as calling scaler.fit(X) then X_scaled = scaler.transform(X)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#understanding-the-kmeans-model-class",
    "href": "session4_newMLDemo/session4v2.html#understanding-the-kmeans-model-class",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Understanding the KMeans model class",
    "text": "Understanding the KMeans model class\nclass sklearn.cluster.KMeans(n_clusters=8, *, init='k-means++', n_init='auto', max_iter=300, \ntol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n\nParameters: Set by user at time of instantiation\n- n_clusters, max_iter, algorithm\n\nAttributes: Store object data\n- cluster_centers_: stores coordinates of cluster centers\n- labels_: stores labels of each point - n_iter_: number of iterations run (will be changed during method run)\n- n_features_in and feature_names_in_: store info about features seen during fit\n\nMethods: Define object behaviors\n- fit(X) -&gt; same as usage as train() -&gt; fit model to data X\n- predict(X) -&gt; predict closest cluster each sample in X belongs to\n- transform(X) -&gt; transform X to cluster-distance space"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-2-create-model",
    "href": "session4_newMLDemo/session4v2.html#step-2-create-model",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 2: Create model",
    "text": "Step 2: Create model\n\n## Choosing 3 clusters b/c we have 3 species\nkmeans = KMeans(n_clusters=3, random_state=42) ## make an instance of the K means class"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-3-fit-model-to-data",
    "href": "session4_newMLDemo/session4v2.html#step-3-fit-model-to-data",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 3: Fit model to data",
    "text": "Step 3: Fit model to data\n\n## the fit\npenguins[\"kmeans_cluster\"] = kmeans.fit_predict(X_scaled)\n\n## now that we fit the model, we should have cluster centers\nprint(\"Coordinates of cluster centers:\", kmeans.cluster_centers_)\n\n\n\nCoordinates of cluster centers: [[-0.95023997  0.55393493]\n [ 0.58644397 -1.09805504]\n [ 1.0886843   0.79503579]]"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#step-5-visualize-and-evaluate",
    "href": "session4_newMLDemo/session4v2.html#step-5-visualize-and-evaluate",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Step 5: Visualize and Evaluate",
    "text": "Step 5: Visualize and Evaluate\nTo do visualization, we can use either seaborn or plotnine. Plotnine is nice because it is just a python port of ggplot!\nTo take at the distribution of our species by bill length and bill depth‚Ä¶\n\n# Plotnine scatterplot of species by bill length/depth\nplot1 = (ggplot(penguins, aes(x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\"))\n + geom_point()\n + ggtitle(\"Penguin Species\")\n + theme_bw())\n\ndisplay(plot1)\n\n\n\n\n\n\n\n\n\n\n\nThe biggest differences between plotnine and ggplot2 syntax are: - With plotnine the whole call is wrapped in () parentheses - Variables are called with strings (\"\" are needed!) - If you don‚Äôt use from plotnine import *, you will need to import each individual function you plan to use!"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#use-function-to-calculate-ari",
    "href": "session4_newMLDemo/session4v2.html#use-function-to-calculate-ari",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Use function to calculate ARI",
    "text": "Use function to calculate ARI\nTo check how good our model is, we can use one of the functions included in the sklearn library\nThe adjusted_rand_score() function evaluates how well the cluster groupings agree with the species groupings while adjusting for chance.\n\n# Calculate clustering performance using Adjusted Rand Index (ARI)\nkmeans_ari = adjusted_rand_score(penguins['species'], penguins[\"kmeans_cluster\"])\nprint(f\"k-Means Adjusted Rand Index: {kmeans_ari:.2f}\")\n\n\n\nk-Means Adjusted Rand Index: 0.82"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#we-can-also-use-methods-on-our-data-structure-to-create-new-data",
    "href": "session4_newMLDemo/session4v2.html#we-can-also-use-methods-on-our-data-structure-to-create-new-data",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "We can also use methods on our data structure to create new data",
    "text": "We can also use methods on our data structure to create new data\n\nWe can use the .groupby() method to help us plot cluster agreement with species label\n\n\n# Count occurrences of each species-cluster-sex combination\n# ( .size gives the count as index, use reset_index to get count column. )\nscatter_data = penguins.groupby([\"species\", \"kmeans_cluster\", \"sex\"]).size().reset_index(name=\"count\")\n\n# Create a heatmap of the cluster assignments by species\nheatmap_plot = (\n    ggplot(scatter_data, aes(x=\"species\", y=\"kmeans_cluster\", fill=\"count\"))\n    + geom_tile(color=\"white\")  # Add white grid lines for separation\n    + scale_fill_gradient(low=\"lightblue\", high=\"darkblue\")  # Heatmap colors\n    + labs(\n        title=\"Heatmap of KMeans Clustering by Species\",\n        x=\"Species\",\n        y=\"KMeans Cluster\",\n        fill=\"Count\"\n    )\n    + theme_bw()\n)\n\n# Display the plot\ndisplay(heatmap_plot)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#we-can-also-use-methods-on-our-data-structure-to-create-new-data-output",
    "href": "session4_newMLDemo/session4v2.html#we-can-also-use-methods-on-our-data-structure-to-create-new-data-output",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "We can also use methods on our data structure to create new data",
    "text": "We can also use methods on our data structure to create new data"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#project-2---knn-classification",
    "href": "session4_newMLDemo/session4v2.html#project-2---knn-classification",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Project 2 -> KNN classification",
    "text": "Project 2 -&gt; KNN classification\nFor our KNN classification, the model is supervised (meaning it is dependent on the outcome ‚Äòy‚Äô data) and therefore we need to split our data into a training and test set.\n\nThe function train_test_split() from scikit-learn is helpful here! Our classifier object has built in methods for fitting models and predicting.\n\n# Splitting dataset into training and testing sets (still using scaled X!)\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#understanding-kneighborsclassifier-class",
    "href": "session4_newMLDemo/session4v2.html#understanding-kneighborsclassifier-class",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Understanding KNeighborsClassifier class",
    "text": "Understanding KNeighborsClassifier class\nclass sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', \nalgorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n\nParameters: Set by user at time of instantiation\n- n_neigbors, weights, algorithm, etc.\n\nAttributes: Store object data\n- classes_: class labels known to the classifier\n- effective_metric_: distance metric used\n- effective_metric_params_: parameters for the metric function\n- n_features_in and feature_names_in_: store info about features seen during fit\n- n_samples_fit_: number of samples in fitted data\n\nMethods: Define object behaviors\n- .fit(X, y) -&gt; fit knn classifier from training dataset (X and y)\n- .predict(X) -&gt; predict class labels for provided data X\n- .predict_proba(X) -&gt; return probability estimates for test data X\n- .score(X, y) -&gt; return mean accuracy on given test data X and labels y"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#making-an-instance-of-kneighborsclassifier-and-fitting-to-training-data",
    "href": "session4_newMLDemo/session4v2.html#making-an-instance-of-kneighborsclassifier-and-fitting-to-training-data",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Making an instance of KNeighborsClassifier and fitting to training data",
    "text": "Making an instance of KNeighborsClassifier and fitting to training data\n\nFor a supervised model, y_train is included in .fit()!\n\n\n## perform knn classification\n# Applying k-NN classification with 5 neighbors\nknn = KNeighborsClassifier(n_neighbors=5) ## make an instance of the KNeighborsClassifier class\n# and set the n_neighbors parameter to be 5. \n\n# Use the fit method to fit the model to the training data\nknn.fit(X_train, y_train)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#once-the-model-is-fit",
    "href": "session4_newMLDemo/session4v2.html#once-the-model-is-fit",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Once the model is fit‚Ä¶",
    "text": "Once the model is fit‚Ä¶\n\nOnce the model is fit, we can look at its attributes (ex: .classes_) which gives the class labels as known to the classifier\n\n\nprint(knn.classes_)\n\n\n\n['Adelie' 'Chinstrap' 'Gentoo']\n\n\n\n\n# Use the predict method on the test data to get the predictions for the test data\ny_pred = knn.predict(X_test)\n\n# Also can take a look at the prediction probabilities, \n# and use the .classes_ attribute to put the column labels in the right order\nprobs = pd.DataFrame(\n    knn.predict_proba(X_test),\n    columns = knn.classes_)\nprobs['y_pred'] = y_pred\n\nprint(\"Predicted probabilities: \\n\", probs.head())\n\n\n\nPredicted probabilities: \n    Adelie  Chinstrap  Gentoo     y_pred\n0     1.0        0.0     0.0     Adelie\n1     0.0        0.0     1.0     Gentoo\n2     1.0        0.0     0.0     Adelie\n3     0.0        0.6     0.4  Chinstrap\n4     1.0        0.0     0.0     Adelie"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#plotnine-scatterplot-for-k-nn-classification-of-test-data",
    "href": "session4_newMLDemo/session4v2.html#plotnine-scatterplot-for-k-nn-classification-of-test-data",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Plotnine scatterplot for k-NN classification of test data",
    "text": "Plotnine scatterplot for k-NN classification of test data\n\nCreate dataframe of unscaled X_test, bill_length_mm, and bill_depth_mm.\nAdd to it the actual and predicted species labels\n\n\n## First unscale the test data\nX_test_unscaled = scaler.inverse_transform(X_test)\n\n## create dataframe \npenguins_test = pd.DataFrame(\n    X_test_unscaled,\n    columns=['bill_length_mm', 'bill_depth_mm']\n)\n\n## add actual and predicted species \npenguins_test['y_actual'] = y_test.values\npenguins_test['y_pred'] = y_pred\npenguins_test['correct'] = penguins_test['y_actual'] == penguins_test['y_pred']"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#plotnine-scatterplot-for-k-nn-classification-of-test-data-1",
    "href": "session4_newMLDemo/session4v2.html#plotnine-scatterplot-for-k-nn-classification-of-test-data-1",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Plotnine scatterplot for k-NN classification of test data",
    "text": "Plotnine scatterplot for k-NN classification of test data\n\n## Build the plot\nplot3 = (ggplot(penguins_test, aes(x=\"bill_length_mm\", y=\"bill_depth_mm\", \ncolor=\"y_actual\", fill = 'y_pred', size = 'correct'))\n + geom_point()\n + scale_size_manual(values={True: 2, False: 5})\n + ggtitle(\"k-NN Classification Results\")\n + theme_bw())\n\ndisplay(plot3)"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#evaluate-knn-performance",
    "href": "session4_newMLDemo/session4v2.html#evaluate-knn-performance",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Evaluate KNN performance",
    "text": "Evaluate KNN performance\n\n## eval knn performance\n# Calculate accuracy and print classification report -&gt; \n# accuracy_score and classification_report are functions! \nknn_accuracy = accuracy_score(y_test, y_pred)\nprint(f\"k-NN Accuracy: {knn_accuracy:.2f}\")\nprint(classification_report(y_test, y_pred))\n\n\n\nk-NN Accuracy: 0.94\n              precision    recall  f1-score   support\n\n      Adelie       0.98      0.98      0.98        48\n   Chinstrap       0.80      0.89      0.84        18\n      Gentoo       0.97      0.91      0.94        34\n\n    accuracy                           0.94       100\n   macro avg       0.92      0.93      0.92       100\nweighted avg       0.94      0.94      0.94       100"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#make-a-summary-table-of-metrics-for-both-models",
    "href": "session4_newMLDemo/session4v2.html#make-a-summary-table-of-metrics-for-both-models",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Make a Summary Table of Metrics for Both Models",
    "text": "Make a Summary Table of Metrics for Both Models\n\n##  making a summary table\n# Creating a summary table\nsummary_table = pd.DataFrame({\n    \"Metric\": [\"k-Means Adjusted Rand Index\", \"k-NN Accuracy\"],\n    \"Value\": [kmeans_ari, knn_accuracy]\n})\nGT(summary_table).show()\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\nk-Means Adjusted Rand Index\n0.8203520973164866\n\n\nk-NN Accuracy\n0.94"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#key-takeaways-from-this-session",
    "href": "session4_newMLDemo/session4v2.html#key-takeaways-from-this-session",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Key Takeaways from This Session",
    "text": "Key Takeaways from This Session\nüîπ Machine learning models in Python are implemented as classes, and model objects are instantiated from these classes.\nüîπ Python modeling workflows make extensive use of both functions and object-oriented structures (e.g., methods and attributes).\nüîπ The consistent use of methods like .fit(), .predict(), and .transform() across libraries encourages code reuse, modularity, and interoperability.\nüîπ A working knowledge of inheritance and mixins is essential for extending functionality, particularly in deep learning frameworks.\nPython‚Äôs object-oriented design makes machine learning pipelines more robust, scalable, and production-ready. üöÄ"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#pre-reading-for-this-session",
    "href": "session4_newMLDemo/session4v2.html#pre-reading-for-this-session",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Pre-Reading for This Session",
    "text": "Pre-Reading for This Session\n\nScikit-learn Documentation\n\nIntroduction to OOP in Python (Real Python)\n\nPlotnine Reference"
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#key-principles-of-oop",
    "href": "session4_newMLDemo/session4v2.html#key-principles-of-oop",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Key Principles of OOP",
    "text": "Key Principles of OOP\n\nEncapsulation: Bundling data and methods together in a single unit.\n\nA StandardScaler object stores mean and variance data and has .fit() and .transform() methods\n\nInheritance: Creating new classes based on existing ones.\n-sklearn.LinearRegression inherits from a general regression model class.\nAbstraction: Hiding implementation details and exposing only essential functionality.\n\ne.g., .fit() works the same way from the outside, regardless of model complexity\n\nPolymorphism: Objects of different types can be treated the same way if they implement the same methods.\n\ne.g., any object with .fit() and .predict() can be passed into a pipeline\nPython‚Äôs duck typing:\n\n‚ÄúIf it walks like a duck and quacks like a duck, then it must be a duck.‚Äù\n\nIf an object has the right attributes and methods, it can be used in the same way as another object of a different class."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#duck-typing",
    "href": "session4_newMLDemo/session4v2.html#duck-typing",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Duck Typing",
    "text": "Duck Typing\n\n‚ÄúIf it quacks like a duck and walks like a duck, it‚Äôs a duck.‚Äù\n\nPython doesn‚Äôt require explicit interfaces. If an object implements the expected methods, it can be used interchangeably with other objects. This is called duck typing.\n\nWe can demonstrate this by defining two new base classes that are different than Dog but also have a speak() method.\n\n\n\nclass Human:\n    def __init__(self, name):\n        self.name = name\n\n    def speak(self):\n        return f\"{self.name} says hello!\"\n\nclass Parrot:\n    def __init__(self, name):\n        self.name = name\n\n    def speak(self):\n        return f\"{self.name} says squawk!\""
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#duck-typing-in-action",
    "href": "session4_newMLDemo/session4v2.html#duck-typing-in-action",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Duck Typing in Action",
    "text": "Duck Typing in Action\nEven though Dog, Human and Parrot are entirely different classes‚Ä¶\n\ndef call_speaker(obj):\n    print(obj.speak())\n\ncall_speaker(Dog(\"Fido\", \"Labrador\"))\ncall_speaker(Human(\"Alice\"))\ncall_speaker(Parrot(\"Polly\"))\n\n\n\nFido says Woof!\nAlice says hello!\nPolly says squawk!\n\n\nThey all implement .speak(), so Python treats them the same!\nIn the context of our work, this would allow us to make a pipeline using models from different libraries that do not share a base class/mixin but have the same methods."
  },
  {
    "objectID": "session4_newMLDemo/session4v2.html#additional-insights",
    "href": "session4_newMLDemo/session4v2.html#additional-insights",
    "title": "Session 4 ‚Äì Object-Oriented Programming and Modeling Libraries",
    "section": "Additional Insights",
    "text": "Additional Insights\nPredictable APIs Make Model Switching Seamless\nOnce you‚Äôre familiar with Python‚Äôs object-method pattern, swapping models (e.g., LogisticRegression ‚Üí RandomForestClassifier) requires only minimal changes.\nscikit-learn Prioritizes Interoperability\nThe standardized class structure enables integration with tools like Pipeline, GridSearchCV, and cross_val_score‚Äîpromoting reusable and testable workflows.\nClass Attributes Support Model Transparency\nUnderstanding common attributes like .coef_, .classes_, and .feature_importances_ is critical for model inspection, debugging, and reporting.\nCustom Classes Are Central in Deep Learning\nFrameworks like PyTorch and TensorFlow rely on subclassing base models‚Äîreinforcing the need to understand object-oriented programming practices.\nMixins Enable Modular Design Across Libraries\nMixins (e.g., ClassifierMixin, TransformerMixin) extend core functionality without redundancy and are a cornerstone of Python‚Äôs library design patterns."
  }
]